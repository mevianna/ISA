## **Modelos Probabilísticos no Naive Bayes**

Até agora, nossos exemplos de classificação de emails usaram implicitamente a distribuição multinomial. Esta é apenas uma das várias distribuições de probabilidade que podemos usar com Naive Bayes, cada uma adequada para diferentes tipos de dados e problemas [1].

No Naive Bayes, a "distribuição" é a nossa **suposição** sobre como os dados (atributos) se comportam dentro de cada classe. É fundamental entender que, independentemente da distribuição escolhida, a regra de decisão do classificador é sempre a mesma: encontrar a classe $C$ que maximiza o produto entre a probabilidade a priori e a verossimilhança.

A fórmula de decisão que vimos na introdução continua sendo nossa base:

$$\hat{C} = \arg\max_C [P(C) \times \prod_{i=1}^{n} P(X_i|C)]$$

ou

$$\hat{C} = \arg\max_C \left[ \text{Prior} \times \left(\prod \text{Verossimilhanças}\right) \right]$$

Na prática, para garantir a estabilidade numérica, trabalhamos com a soma dos logaritmos. Assim, a fórmula de decisão para **qualquer** classificador Naive Bayes assume a seguinte estrutura universal:

$$ \hat{C} = \arg\max_C \left[ \log P(C) + \sum_{i=1}^{n} \log P(X_i|C) \right] $$

Essa estrutura de "soma de logaritmos" é o template prático que veremos em todos os modelos a seguir. O que os diferencia é **a forma como cada termo da fórmula é calculado**.

### 1. O Que Permanece Fixo: O Prior, $P(C)$

A **Probabilidade a Priori** é sempre calculada da mesma forma: é a frequência geral de cada classe no conjunto de treinamento. Portanto, o termo $\log P(C)$ na nossa fórmula **não muda**, independentemente do modelo que usamos para os atributos.

### 2. O Que Muda: A Verossimilhança, $P(X_i|C)$

A **Verossimilhança** é a parte "especialista" do classificador. O termo $\log P(X_i|C)$ dentro do somatório é a única peça que se adapta à natureza dos dados. A escolha do modelo é, na verdade, a escolha de qual ferramenta matemática usar para calcular essa verossimilhança:

A **Verossimilhança** é a parte do cálculo que se adapta à natureza dos dados. A escolha do modelo é, na verdade, a escolha de qual ferramenta matemática usar para calcular essa verossimilhança:

- Se os atributos são **contagens** (como palavras em um texto), usamos a abordagem **Multinomial**.
- Se os atributos são de **presença/ausência** (sim/não), usamos a abordagem **Bernoulli**.
- Se os atributos são **contínuos** (como altura ou preço), usamos a abordagem **Gaussiana**, que nos dá uma densidade de probabilidade $f(X_i|C)$ para usarmos dentro do logaritmo.

Escolher o modelo correto para calcular a verossimilhança é fundamental para o sucesso do classificador. Com essa estrutura em mente, vamos agora analisar em detalhe como cada um desses modelos funciona.
