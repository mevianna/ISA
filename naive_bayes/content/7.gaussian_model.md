# Modelo Gaussiano (Gaussian Naive Bayes)

Até agora, trabalhamos exclusivamente com **variáveis discretas** — isto é, atributos que assumem valores específicos e contáveis. No caso dos modelos Multinomial e Bernoulli, lidamos com contagens de palavras ou presenças binárias (0 ou 1).

No entanto, muitos problemas do mundo real envolvem dados que não são contáveis, mas sim medidos, como altura, temperatura ou preço. É aqui que entra o **Gaussian Naive Bayes**.

> [!NOTE]
> **Diferença Essencial: Variáveis Discretas vs. Contínuas**
>
> - **Variáveis Discretas**: Assumem valores específicos e contáveis. Exemplos: número de palavras, presença/ausência de características, número de cliques.
> - **Variáveis Contínuas**: Podem assumir qualquer valor dentro de um intervalo. Exemplos: altura, peso, temperatura, preço, velocidade.
>
> Essa distinção é fundamental, pois a maneira de calcular a "chance" de um valor ocorrer muda completamente entre os dois tipos.

### Quando Usar o Modelo Gaussiano

O **Gaussian Naive Bayes** é a variante do classificador ideal quando seus atributos (features) são **variáveis contínuas**. Ele assume que, para cada classe, os valores de um atributo seguem uma distribuição normal (também conhecida como gaussiana ou "curva de sino").

Exemplos típicos de uso incluem:

- **Diagnóstico médico**: Classificar pacientes com base em altura, peso, pressão arterial ou níveis de colesterol.
- **Setor financeiro**: Prever o risco de crédito com base em renda, idade ou valor de empréstimo.
- **Sensores e IoT**: Identificar anomalias com base em medições de temperatura, umidade ou velocidade.

### Conceitos Fundamentais: Média e Variância

Antes de mergulharmos no modelo, precisamos relembrar dois conceitos estatísticos que são a base da distribuição normal:

#### Média ($\mu$)
A **média** é o centro de gravidade dos dados, representando o valor central ou "típico" de um conjunto.

$$\mu = \frac{1}{n} \sum_{i=1}^{n} x_i$$

#### Variância ($\sigma^2$)
A **variância** mede a dispersão dos dados em torno da média. Uma variância alta indica que os dados estão muito espalhados; uma variância baixa significa que eles estão concentrados perto da média. O **desvio padrão** ($\sigma$) é a raiz quadrada da variância.

$$\sigma^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2$$

> [!NOTE]
> **Por que Média e Variância?**
>
> A distribuição normal é **completamente definida** por apenas esses dois parâmetros. Se você conhece a média e a variância de um conjunto de dados que se distribui normalmente, você conhece a forma exata da sua distribuição e pode descrevê-la matematicamente.

### Distribuição Normal (Gaussiana)

A distribuição normal é talvez a mais famosa da estatística, reconhecida por sua forma simétrica de **curva de sino**. Ela descreve muitos fenômenos naturais e processos onde os valores tendem a se agrupar em torno de uma média central. A maioria dos valores fica perto da média, e valores mais distantes (tanto para mais quanto para menos) tornam-se progressivamente mais raros.

Para calcular a curva, usamos a **função de densidade de probabilidade** (PDF, na sigla em inglês). Essa função nos dá a altura da curva em qualquer ponto $x$:

$f(x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$

> [!IMPORTANT]
> **Verossimilhança é a Altura da Curva!**
>
> Aqui está uma mudança de conceito crucial em relação aos modelos Bernoulli e Multinomial.
>
> - Em modelos **discretos**, a verossimilhança $P(\text{palavra}|\text{classe})$ era uma probabilidade real e direta.
> - Em modelos **contínuos**, a probabilidade de um valor *exato* ocorrer é zero ($P(X=x) = 0$).
>
> Então, o que usamos? Usamos a **verossimilhança (likelihood)**, que para a distribuição gaussiana é o valor da função de densidade $f(x)$ no ponto de interesse.
>
> Pense nisso como a **altura da curva de sino** no ponto exato do seu dado. Uma altura maior significa que o dado é mais "compatível" ou "verossímil" com aquela distribuição de classe. O Naive Bayes usa essa altura como um score para comparar qual classe "explica" melhor o dado observado.

### Classificador Gaussian Naive Bayes

O processo de classificação com Gaussian Naive Bayes segue a mesma lógica de sempre, mas com um cálculo de verossimilhança diferente.

1.  **Treinamento**: Para cada classe $C$ e cada atributo contínuo $X_i$:
    * Calcule a média desse atributo para todos os exemplos da classe $C$: $\mu_{i,C}$
    * Calcule a variância desse atributo para todos os exemplos da classe $C$: $\sigma_{i,C}^2$

2.  **Classificação**: Para um novo dado com atributos $(x_1, x_2, ..., x_n)$, calculamos um score para cada classe usando a fórmula do Naive Bayes (geralmente em escala logarítmica para evitar underflow):

    $\hat{C} = \arg\max_C \left[ \log P(C) + \sum_{i=1}^{n} \log f(x_i | \mu_{i,C}, \sigma_{i,C}^2) \right]$

    Onde $f(x_i | ...)$ é a verossimilhança dada pela função de densidade da distribuição normal que vimos acima.

### Exemplo Prático: Classificação de Risco Cardíaco

### 1. O Problema

Vamos classificar pacientes em `Baixo Risco` ou `Alto Risco` para complicações cardíacas com base em dois exames de rotina:

* `Colesterol LDL (mg/dL)`
* `Pressão Arterial Sistólica (mmHg)`

### 2. Perfil das Classes (Treinamento)

Com base em dados históricos, o modelo aprendeu os seguintes perfis (parâmetros) para cada classe:

**Classe `Baixo Risco`**
* **Colesterol LDL**: Perfil saudável, com média $\mu = 100 \text{ mg/dL}$ e desvio padrão $\sigma = 15$.
* **Pressão Arterial**: Perfil saudável e, crucialmente, **muito consistente**. A média é $\mu = 115 \text{ mmHg}$ com desvio padrão $\sigma = 5$.

**Classe `Alto Risco`**
* **Colesterol LDL**: Média elevada de $\mu = 160 \text{ mg/dL}$ e desvio padrão $\sigma = 30$
* **Pressão Arterial**: Média elevada de $\mu = 145 \text{ mmHg}$ e desvio padrão $\sigma = 10$.

### 3. O Paciente em Análise

Um novo paciente chega com os seguintes resultados:

* **Colesterol LDL**: 150 mg/dL
* **Pressão Arterial**: 130 mmHg

### 4. Análise Gráfica e Cálculo da Verossimilhança

Abaixo estão os gráficos das quatro distribuições, com um "X" preto marcando onde os dados do nosso paciente se encaixam.

![Gráficos das distribuições de Risco Cardíaco](.\figures\risco_cardiaco_distribuicoes.png)

Vamos analisar os números por trás dos gráficos, calculando a verossimilhança (a altura da curva no ponto do paciente) para cada caso.

#### Cálculos Detalhados

* **Para a classe `Baixo Risco`**:
    * $f(\text{colesterol}=150 | \text{Baixo Risco}) \approx 0.000103$
    * $f(\text{pressão}=130 | \text{Baixo Risco}) \approx 0.000886$
    > **Análise Chave**: Note como a verossimilhança da pressão é baixíssima. Como a curva de `Baixo Risco` para pressão é muito "estreita" (baixa variância), o valor 130 está a 3 desvios-padrão de distância da média de 115, tornando-o um evento extremamente raro e "estatisticamente incompatível" com este grupo.

* **Para a classe `Alto Risco`**:
    * $f(\text{colesterol}=150 | \text{Alto Risco}) \approx 0.012579$
    * $f(\text{pressão}=130 | \text{Alto Risco}) \approx 0.012952$
    > **Análise Chave**: Ambos os valores são muito plausíveis para a classe `Alto Risco`. Estão próximos das médias e dentro de curvas de distribuição mais "flexíveis" (maior variância), resultando em verossimilhanças muito maiores.

#### Scores Finais

Usando a fórmula do Naive Bayes em escala logarítmica e assumindo priors iguais ($P(\text{Baixo Risco}) = P(\text{Alto Risco}) = 0.5$):

* **Score (Baixo Risco)**: $\log(0.5) + \log(0.000103) + \log(0.000886) \approx \mathbf{-16.90}$
* **Score (Alto Risco)**: $\log(0.5) + \log(0.012579) + \log(0.012952) \approx \mathbf{-9.42}$

### 5. Conclusão

O score para **Alto Risco (-9.42)** é significativamente maior (menos negativo) que o de Baixo Risco (-16.90).
