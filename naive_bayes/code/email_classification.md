# Exemplo: Classifica√ß√£o de e-mails com Naive Bayes

O principal objetivo deste algoritmo √© demonstrar como o m√©todo Naive Bayes pode ser muito eficaz em tarefas de classifica√ß√£o, como a detec√ß√£o de spam. A seguir, apresentamos um passo a passo did√°tico e de f√°cil compreens√£o, para que voc√™ possa reproduzir a implementa√ß√£o com outros conjuntos de dados e, assim, praticar e se divertir! :smile:




<img src="https://media1.tenor.com/m/3AQDvhSiPpMAAAAC/dog-hacker.gif" width="300" />


## C√≥digo

### Importar bibliotecas
``` python
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.feature_extraction.text import TfidfVectorizer
from collections import Counter
```
- pandas as pd ‚Üí para ler o CSV e manipular o DataFrame.

- MultinomialNB ‚Üí classificador Naive Bayes.

- train_test_split ‚Üí divis√£o entre treino e teste.

- TfidfVectorizer ‚Üí (importado dentro do c√≥digo, mas usado corretamente).

- SMOTE ‚Üí para balancear os dados.
  
- TfidfVectorizer ‚Üí usada para transformar texto em n√∫meros.

- Counter ‚Üí √© uma estrutura de dados que serve para contar a frequ√™ncia de elementos em um iter√°vel.

- confusion_matrix, seaborn, matplotlib.pyplot ‚Üí para visualizar a matriz de confus√£o.

### Carregar e preparar os dados
``` python
ds = pd.read_csv("/content/spam.csv")
ds["spam"] = ds["Category"].apply(lambda x: 1 if x == "spam" else 0)
y = ds.iloc[:, 2].values
X = ds["Message"]
vectorizer = TfidfVectorizer()
X_tfidf = vectorizer.fit_transform(X)
X_treino, X_teste, y_treino, y_teste = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)
```
- Carrega o dataset CSV ‚Üí le o arquivo CSV chamado spam.csv e salva o conte√∫do no DataFrame ds usando a biblioteca pandas.
  
- Cria uma nova coluna "spam" com r√≥tulos bin√°rios (0 e 1).
  - Acessa a coluna Category, que cont√©m r√≥tulos de texto como "spam" ou "ham" (n√£o-spam)
  - Usa apply() com uma fun√ß√£o lambda para converter esses textos em n√∫meros: "spam" ‚Üí 1, qualquer outro valor (como "ham") ‚Üí 0
  - Cria uma nova coluna chamada "spam" no DataFrame com esses valores
    
- Separa os r√≥tulos (y).
  
- Separa as mensagens (X).

- Vetoriza√ß√£o com TfidfVectorizer ‚Üí transforma os textos da coluna Message em vetores num√©ricos esparsos com base na frequ√™ncia e relev√¢ncia de cada palavra (TF-IDF = Term Frequency ‚Äì Inverse Document Frequency).

- Divide os dados em 80% para treino e 20% para teste ‚Üí stratify=y garante que a propor√ß√£o de classes (spam/ham) seja mantida igual nas duas partes.

- random_state = 42 ‚Üí Garante que a divis√£o sempre ocorra da mesma forma (reprodutibilidade).

- stratify = y ‚Üí Garante que a propor√ß√£o de spam e n√£o spam seja mantida em ambos os conjuntos.

> [!IMPORTANT]
> Sem stratify, o modelo poderia acabar com muito menos spam no teste ou no treino, o que prejudicaria o aprendizado e avalia√ß√£o.

> [!Note]
>Por que usar TF-IDF?
>  - D√° peso maior √†s palavras que realmente t√™m import√¢ncia.
>  - Ignora palavras comuns (como "e", "a", "de", etc.).
>  - √â r√°pido e eficiente.
>  - Funciona muito bem com modelos lineares como Naive Bayes.

### Oversampling
gerar dados sint√©ticos para a classe minorit√°ria (neste caso, spam).

> [!Note]
>Oversampling √© uma t√©cnica usada em machine learning para lidar com conjuntos de dados desbalanceados ‚Äî ou seja, quando uma classe (ex: spam) tem muito menos exemplos do que a outra (ex: n√£o spam).

``` python
print("Antes do oversampling:", Counter(y_treino))
```
[![image.png](https://i.postimg.cc/bwXXTV7s/image.png)](https://postimg.cc/D8cYf6yT)
``` python
smote = SMOTE(random_state=42)
X_treino_smote, y_treino_smote = smote.fit_resample(X_treino, y_treino)
```
- Cria um objeto SMOTE, que vai gerar dados sint√©ticos para a classe minorit√°ria (neste caso, spam).
- SMOTE faz o "oversampling":
  - Ele gera exemplos sint√©ticos da classe minorit√°ria (spam = 1).
  - O conjunto de treino resultante (X_treino_smote) agora tem a mesma quantidade de exemplos das duas classes.

``` python
print("Ap√≥s o oversampling:", Counter(y_treino_smote))
```
[![image.png](https://i.postimg.cc/LX4hs8vK/image.png)](https://postimg.cc/jW9RgKGZ)

### Treinar, testar e visualizar os resultados
``` python
modelo = MultinomialNB()
modelo.fit(X_treino_smote, y_treino_smote)
previsoes = modelo.predict(X_teste)
previsoes
```
[![image.png](https://i.postimg.cc/pTBLjhqX/image.png)](https://postimg.cc/sQvzd2kt)
``` python
y_teste
```
[![image.png](https://i.postimg.cc/XJBTMTyM/image.png)](https://postimg.cc/5Y1PLK3p)
``` python
modelo.score(X_teste, y_teste)
```
[![image.png](https://i.postimg.cc/TwQW6489/image.png)](https://postimg.cc/jwwj6vSw)
``` python
cm = confusion_matrix(y_teste, previsoes)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title('Matriz de Confus√£o')
plt.show()
```
[![image.png](https://i.postimg.cc/gcC6PRQ1/image.png)](https://postimg.cc/XXgvfZVg)

- Para visualizar os resultados das previs√µes do modelo usamos a matriz de confus√£o, que mostra com detalhes quantos acertos e erros o modelo cometeu para cada classe (spam e n√£o-spam).

### Conclus√µes
üìå ***O modelo √© eficaz para detectar spam***
  - Acerta a maioria das mensagens, como mostrado pela alta acur√°cia de 97%.
  - Ele √© capaz de prever corretamente tanto spam quanto n√£o spam, o que √© confirmado pela matriz de confus√£o.


üìå ***O uso do SMOTE foi essencial***
  - Com o oversampling, igualamos o n√∫mero de exemplos de cada classe, o que ajuda o modelo a aprender melhor como identificar spam.
  - Evita que o modelo "ignore" a classe minorit√°ria (spam).


üìå ***Pipeline bem estruturado***
  - Pr√©-processamento.
  - Vetoriza√ß√£o.
  - Divis√£o estratificada.
  - Balanceamento com SMOTE.
  - Treinamento.
  - Avalia√ß√£o com m√©trica e matriz.

## üëæ **Contribuidores**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/112569754?v=4" width=115><br><sub>Alice Motin</sub>](https://github.com/AliceMotin) | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/206122594?v=4" width=115><br><sub>Arthur Janing</sub>](https://github.com/Arthur-Janing) | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/147776134?v=4" width=115><br><sub>Caroline Lanzuolo</sub>](https://github.com/carol-lanzu) | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/171816351?v=4" width=115><br><sub>Mateus Kramer</sub>](https://github.com/mateuskramer) 
| :---: | :---: | :---: | :---: |

