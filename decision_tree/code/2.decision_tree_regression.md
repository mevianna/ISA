# Portuguese Version

## Explicações gerais

### Sobre o dataset
Esse conjunto de dados é usado para prever a **progressão da diabetes** um ano após a coleta de dados iniciais dos pacientes. É, portanto, um problema de regressão.

#### Estrutura do dataset:
- Contém 442 amostras de pacientes com diabetes.
- Cada amostra possui 10 atributos numéricos: idade, sexo, índice de massa corporal (IMC), pressão arterial média, e seis medições sanguíneas relacionadas, como níveis de colesterol total, lipoproteínas (LDL e HDL), razão colesterol/HDL, triglicerídeos e glicose.

A variável-alvo (target) representa uma medida quantitativa da progressão da doença.

Para maior detalhamento sobre o dataset, acesse:
https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html

### Sobre como o código foi estruturado
O código foi **pensado para complementar** didaticamente o **tutorial anterior** ([Árvore de classificação para câncer de mama](1.decision_tree_classification.md)). Nele, tínhamos avaliado quatro abordagens:
- Sem poda
- Com pré-poda
- Com pós-poda
- Com pré e pós-poda combinadas

Além disso, apresentamos a visualização das árvores, matrizes de confusão, tabelas de desempenho, profundidade, número de nós, e a importância das características.

**Neste tutorial de regressão, poderíamos seguir a mesma estrutura e visualizações. No entanto, para variar a abordagem e enriquecer o aprendizado, optamos por modificar a forma de análise:**

Utilizamos **três estratégias:** 
- **Sem poda**
- **Com pré-poda**
- **Com pós-poda**
- 
(não aplicamos pré e pós-poda combinadas para simplificar nossa análise, haja vista que, em muitos casos, não há ganhos significativos).


Além da visualização das árvores e das métricas MSE e R², apresentamos **outros tipos de gráficos** que ajudam a compreender melhor o comportamento dos modelos, tais como:
- **Valores reais vs. valores preditos** para avaliar visualmente a qualidade das previsões.
- **Trade-off entre complexidade da árvore e erro** (MSE), **variando** o parâmetro **ccp_alpha**.
- **Número de nós e profundidade vs. alpha**, para entender como a árvore é simplificada com a pós-poda.

Essas mudanças tornam este tutorial complementar ao de classificação, focando em outros aspectos visuais e conceituais importantes para modelos de regressão.

## Código

### Importar bibliotecas

``` python
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
```
- pandas e numpy: bibliotecas para manipulação de dados.
- DecisionTreeRegressor e plot_tree: para criar e visualizar uma árvore de regressão. 
- load_diabetes: dataset exemplo da biblioteca scikit-learn.
- train_test_split: para dividir os dados em treino e teste.
- mean_squared_error, r2_score: métricas para avaliar o modelo.
- matplotlib.pyplot: para visualizações gráficas.

### Carregar e preparar os dados
 ``` python
data = load_diabetes()
X, y = data.data, data.target
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=123
)
 ```
- Carregamos o dataset Diabetes para a variável data.
- X recebe as features (10 atributos numéricos relacionados a exames médicos).
- y recebe a variável alvo contínua (uma medida quantitativa da progressão da doença).
- Dividimos os dados em conjuntos de treino e teste:
  - 70% dos dados vão para treino (X_train, y_train)
  - 30% vão para teste (X_test, y_test)
  - random_state=42 garante que a divisão seja reprodutível (sempre a mesma).

### Treinar árvore SEM poda
 ``` python
reg_none = DecisionTreeRegressor(random_state=123)
reg_none.fit(X_train, y_train)
 ```

### Avaliar o modelo SEM poda
 ``` python
y_pred_none = reg_none.predict(X_test)
mse_none = mean_squared_error(y_test, y_pred_none)
r2_none = r2_score(y_test, y_pred_none)

print(f"MSE (sem poda): {mse_none:.3f}")
print(f"R² (sem poda): {r2_none:.3f}")

plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred_none, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Valores Reais")
plt.ylabel("Valores Preditos")
plt.title("Valores Reais vs Preditos - Sem poda")
plt.show()
 ```

### Treinar modelo com pré-poda (exemplo com max_depth=3)
 ``` python
reg_pre = DecisionTreeRegressor(max_depth=3, random_state=123)
reg_pre.fit(X_train, y_train)
```

### Avaliar modelo com pré-poda
 ``` python
y_pred_pre = reg_pre.predict(X_test)
mse_pre = mean_squared_error(y_test, y_pred_pre)
r2_pre = r2_score(y_test, y_pred_pre)

print(f"MSE (pré-poda): {mse_pre:.3f}")
print(f"R² (pré-poda): {r2_pre:.3f}")

plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred_pre, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Valores Reais")
plt.ylabel("Valores Preditos")
plt.title("Valores Reais vs Preditos - Pré-poda (max_depth=3)")
plt.show()
```

### Pós-poda
 ``` python
# Obter valores de alpha e árvores podadas associadas
path = reg_none.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas, impurities = path.ccp_alphas, path.impurities

# Treinar uma árvore para cada valor de alpha
regs = []
for ccp_alpha in ccp_alphas:
    reg = DecisionTreeRegressor(random_state=123, ccp_alpha=ccp_alpha)
    reg.fit(X_train, y_train)
    regs.append(reg)

# Avaliar erro de treino e teste para cada árvore
train_errors = [mean_squared_error(y_train, reg.predict(X_train)) for reg in regs]
test_errors = [mean_squared_error(y_test, reg.predict(X_test)) for reg in regs]

# Plotar o erro vs alpha para visualizar trade-off
plt.figure(figsize=(8,5))
plt.plot(ccp_alphas, train_errors, marker='o', label='Erro treino')
plt.plot(ccp_alphas, test_errors, marker='o', label='Erro teste')
plt.xlabel('Alpha')
plt.ylabel('Erro quadrático médio (MSE)')
plt.title('Trade-off entre complexidade da árvore e erro')
plt.legend()
plt.show()

# Selecionar melhor alpha baseado no menor erro no teste
best_alpha = ccp_alphas[np.argmin(test_errors)]
print(f"Melhor alpha: {best_alpha:.5f}")

# Treinar árvore final com melhor alpha
reg_poda = DecisionTreeRegressor(random_state=123, ccp_alpha=best_alpha)
reg_poda.fit(X_train, y_train)

# Avaliar o modelo podado
y_pred_poda = reg_poda.predict(X_test)
mse_poda = mean_squared_error(y_test, y_pred_poda)
r2_poda = r2_score(y_test, y_pred_poda)

print(f"MSE (poda pós-treinamento): {mse_poda:.3f}")
print(f"R² (poda pós-treinamento): {r2_poda:.3f}")

# Gráfico Valores Reais vs Preditos - podado
plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred_poda, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Valores Reais")
plt.ylabel("Valores Preditos")
plt.title("Valores Reais vs Preditos - Pós-poda")
plt.show()

# Visualizar árvore podada (opcional)
plt.figure(figsize=(20,10))
plot_tree(reg_poda, filled=True, feature_names=data.feature_names, rounded=True)
plt.title("Árvore de Decisão Podada (pós-treinamento)")
plt.show()
```


