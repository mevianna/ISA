# Portuguese Version

## Explicações gerais

### Sobre o dataset
Esse conjunto de dados é usado para classificar **tumores de mama** como **malignos (cancerígenos)** ou **benignos (não cancerígenos)** com base em características extraídas de imagens de exames. É, portanto, um problema de classificação binária.

#### Estrutura do dataset:
- Contém 569 amostras (pacientes), com 212 malígnos e 357 benignos.
- São analisados 30 atributos numéricos relacionados, por exemplo, a características dos tumores, como o raio, textura, perímetro, área, suavidade etc.

Para maior detalhamento sobre o dataset, acesse: 
https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html

### Sobre como o código foi estruturado


## Código

### Importar bibliotecas
``` python
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
```
- pandas (pd): Usada para manipulação e análise de dados em formato de tabelas (DataFrames).
- sklearn: scikit-learn (sklearn) é uma biblioteca em Python utilizada para Machine Learning. Nos permite treinar modelos, processar dados e avaliar seus desempenhos.

  - sklearn.datasets.load_breast_cancer:
Função para carregar o dataset Breast Cancer Wisconsin (Diagnostic), que contém dados para classificação de tumores.

  - sklearn.tree.DecisionTreeClassifier:
Implementa o modelo de Árvore de Decisão para classificação. Utilizado para treinar o classificador que vai prever se um tumor é benigno ou maligno.

  - sklearn.model_selection.train_test_split:
Função para dividir os dados em conjuntos de treino e teste.

  - sklearn.metrics.accuracy_score:
Métrica para calcular a acurácia (percentual de acertos) do modelo preditivo.

### Carregar e preparar os dados
``` python
data = load_breast_cancer()
X, y = data.data, data.target
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
```
- Carrega o dataset Breast Cancer Wisconsin para a variável data.
- X recebe as features (30 atributos numéricos).
- y recebe os rótulos/classes (benigno ou maligno).
- Divide os dados em conjuntos de treino e teste:
  - 70% dos dados vão para treino (X_train, y_train)
  - 30% vão para teste (X_test, y_test)
  - random_state=42 garante que a divisão seja reprodutível (sempre a mesma).
  - stratify=y mantém a proporção original das classes (maligno/benigno) nos dois conjuntos.
 
### Treinar o modelo. 
No caso, faremos isso 4 vezes para propósitos didáticos: sem poda, com pré-poda, com pós-poda, com pré-poda e pós-poda.

#### 1. Sem poda
``` python
clf_sem_poda = DecisionTreeClassifier(random_state=42)
clf_sem_poda.fit(X_train, y_train)
```

#### 2. Com pré-poda
``` python
clf_pre_poda = DecisionTreeClassifier(max_depth=4, random_state=42)
clf_pre_poda.fit(X_train, y_train)
```
#### 3. Com pós-poda
``` python
# Primeiro, encontramos os possíveis valores de alpha
path = clf_sem_poda.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas = path.ccp_alphas

# Vamos testar cada alpha para ver qual dá a melhor acurácia no teste
best_alpha = 0
max_acc = 0

for alpha in ccp_alphas:
    # Ignora o último alpha que remove todos os nós
    if alpha >= path.ccp_alphas[-2]:
        continue
    
    temp_clf = DecisionTreeClassifier(random_state=42, ccp_alpha=alpha)
    temp_clf.fit(X_train, y_train)
    acc = accuracy_score(y_test, temp_clf.predict(X_test))
    
    if acc > max_acc:
        max_acc = acc
        best_alpha = alpha

# Agora, criamos o modelo final de pós-poda com o melhor alpha encontrado
clf_pos_poda = DecisionTreeClassifier(random_state=42, ccp_alpha=best_alpha)
clf_pos_poda.fit(X_train, y_train)
```
#### 4. Com pré-poda e pós-poda
``` python
# Usamos os mesmos parâmetros dos cenários 2 e 3 juntos
clf_pre_pos_poda = DecisionTreeClassifier(random_state=42, max_depth=4, ccp_alpha=best_alpha)
clf_pre_pos_poda.fit(X_train, y_train)
```

### Tabela comparativa dos resultados
``` python
modelos = {
    "Sem Poda": clf_sem_poda,
    "Apenas Pré-Poda (max_depth=4)": clf_pre_poda,
    f"Apenas Pós-Poda (ccp_alpha={best_alpha:.4f})": clf_pos_poda,
    "Pré + Pós Poda": clf_pre_pos_poda
}

# Criando lista para o DataFrame
results = []
for nome, modelo in modelos.items():
    res = {
        "Estratégia": nome,
        "Acurácia Treino": accuracy_score(y_train, modelo.predict(X_train)),
        "Acurácia Teste": accuracy_score(y_test, modelo.predict(X_test)),
        "Profundidade": modelo.get_depth(),
        "Nós Totais": modelo.tree_.node_count
    }
    results.append(res)

# Criando e exibindo a tabela com pandas
tabela = pd.DataFrame(results)
print(tabela.round(4))
```

Output:
| Estratégia                       | Acurácia Treino | Acurácia Teste | Profundidade | Nós Totais |
|----------------------------------|------------------|----------------|---------------|-------------|
| Sem Poda                         | 1.0000           | 0.9181         | 6             | 31          |
| Apenas Pré-Poda (max_depth=4)    | 0.9925           | 0.9240         | 4             | 23          |
| Apenas Pós-Poda (ccp_alpha=0.0030)| 0.9899           | 0.9357         | 4             | 17          |
| Pré-Poda e Pós-Poda                   | 0.9899           | 0.9357         | 4             | 17          |
