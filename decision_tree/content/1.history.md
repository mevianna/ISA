# English Version


# Portuguese Version

A história das árvores de decisão pode ser traçada a partir de duas linhas principais de desenvolvimento. A primeira está mais relacionada à classificação, tendo origem no algoritmo CLS (Concept Learning System), que mais tarde deu origem a algoritmos como o ID3 e o C4.5. A segunda linha está mais conectada à regressão, com destaque para o sistema AID (Automatic Interaction Detector), que originou algoritmos como o CART. Abordaremos tudo isso com mais detalhes a seguir!

## Classificação

### CLS (Concept Learning System)

As árvores de decisão têm suas origens atreladas ao desenvolvimento do **CLS (Concept Learning System)**, criado por **Hunt, Marin e Stone** na década de 1960. Esse sistema é considerado o **"patriarca"** da chamada família **TDIDT (Top-Down Induction of Decision Trees)**[1], amplamente explorada no campo de Machine Learning. 

>[!NOTE]
> O CLS é considerado um dos primeiros métodos a empregar a abordagem de **indução descendente para construção de árvores de decisão**.[1]

> "Indução" significa criar um modelo geral a partir de exemplos específicos
> 
> "Descendente" significa que a árvore é construída do topo (raiz) para baixo (folhas)

O sistema de Hunt constrói árvores de decisão tentando **minimizar o custo da classificação**, que envolve dois fatores: o custo de medir uma característica do objeto e o custo de errar a classificação [1]. 

O custo de medir uma característica do objeto se refere, por exemplo, a quando a medição é cara ou difícil de obter. Já o custo de errar a classificação está relacionado a decidir que o objeto pertence a uma classe quando, na verdade, ele pertence a outra.

Para minimizar o custo, ele usa uma estratégia de **“lookahead”** [1]. Isto é, ele simula alguns passos à frente antes de tomar a decisão de como dividir a árvore.

A partir do que foi desenvolvido por Hunt et al, temos o ID3.

### ID3
O ID3 foi desenvolvido por J.R. Quinlan durante o final da década de 70 e início da década de 80. Uma mudança fundamental foi a **substituição da avaliação baseada em custo por uma função de avaliação orientada a informações**[1]. 

Essa nova avaliação funciona da seguinte forma:
1. Começa com uma amostra pequena dos dados (janela)
2. Cria-se uma árvore que acerta essa amostra.
3. Testa-se a árvore no restante dos dados.
4. Se acertar tudo, o processo termina. Se errar, os exemplos incorretos são adicionados à amostra e o processo se repete.

### C4.5
Foi um algoritmo apresentado também por Quinlan. O C4.5, desenvolvido na década de 90, é uma evolução do ID3 e trouxe diversas melhorias, como a capacidade de lidar com dados contínuos, tratar valores ausentes, aplicar a poda da árvore após sua construção e utilizar a razão de ganho para a escolha dos atributos, evitando o viés presente no ID3[2].


## Regressão

### CART


## Modelos posteriores



## Referências
[1]  Quinlan, J.R. Induction of decision trees. Mach Learn 1, 81–106 (1986). https://doi.org/10.1007/BF00116251

[2] Badr HSSINA, Abdelkarim MERBOUHA, Hanane EZZIKOURI and Mohammed ERRITALI, “A comparative study of decision tree ID3 and C4.5” International Journal of Advanced Computer Science and Applications(IJACSA), Special Issue on Advances in Vehicular Ad Hoc Networking and Applications 2014, 2014. http://dx.doi.org/10.14569/SpecialIssue.2014.040203

