# English Version

# Portuguese Version

## Ideias introdutórias

A árvore de decisão é um modelo que serve tanto para classificação e regressão. [1] 

> [!NOTE]
> Lembrando que os problemas de regressão preveem números, como o preço de uma casa. Os de classificação são aqueles que preveem “rótulos” ou “categorias”, como se um email se encaixa na categoria “spam” ou “não spam”.
 
Como em uma árvore, temos raízes e folhas. No caso do modelo, a raíz é o nó superior e contém todo o conjunto de dados. As folhas são os nós finais e representam as respostas previstas pelo modelo.[1]

### Mas como saímos da raíz (conjunto de dados) e chegamos nas folhas (respostas finais)?

Basicamente, submetemos os dados à perguntas, as quais chamamos de “testes”. Já na raíz podemos ver o primeiro teste. Se a resposta for verdadeira, vamos ao nó da esquerda, se for falsa, vamos ao nó da direita.[1]


Por exemplo:

(exemplo aqui)


> [!IMPORTANT]
> A ordem em que os testes são feitos muda a estrutura da árvore e interfere diretamente na eficiência do algoritmo!

## Qual a melhor ordem de testes?

Devemos ter o quanto antes o teste que:
- Para regressão, faz ter menor variabilidade entre os valores dos dados separados.[2]
  
- Para classificação, mais separa as classes.[2]


De forma mais objetiva, temos a minimizacão de algumas funcoes específicas. Vamos considerá-las a partir de agora:


### Regressão
Devemos ter o **menor MSE (Erro Quadrático Médio)** possível.
(formula)


### Classificacao
Temos **duas formas** de avaliar se a divisão está promovendo um bom desempenho: **entropia (cross-entropy) e o índice de Gini**.

-> Entropia

(fórmula)










## Referências:

[1] Müller, A. C., & Guido, S. (2016). Introduction to machine learning with Python: A guide for data scientists. O'Reilly Media.

[2] Bishop, C. M. (2006). Pattern recognition and machine learning. Springer.
