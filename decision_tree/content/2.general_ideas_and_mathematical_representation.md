# English Version

## Introductory Ideas

A decision tree is a model that can be used for both classification and regression.[1]  

> [!NOTE]  
> Remember that regression problems predict numbers, such as the price of a house. Classification problems, on the other hand, predict “labels” or “categories,” such as whether an email belongs to the “spam” or “not spam” category.  

Just like in a tree, we have roots and leaves. In the model, the root is the top node and contains the entire dataset. The leaves are the final nodes and represent the predictions made by the model.[1]  

### But how do we go from the root (dataset) to the leaves (final answers)?

Basically, we submit the data to questions, which we call “tests.” Already at the root, we can see the first test. If the answer is true, we move to the left node; if it’s false, we move to the right node.[1]  

We repeat this process until we reach a leaf!  

#### For example:

Let’s say we have three different fruits: **apple**, **orange**, and **cherry**. Based on characteristics like color and weight, we can build a tree to classify them.

```mermaid
flowchart TD
    A[Is the fruit's color red?]
    A -- Yes --> B[Is the weight greater than 75g?]
    A -- No --> C[Orange]
    B -- Yes --> D[Apple]
    B -- No --> E[Cherry]

    style A fill:#bbdefb,stroke:#333,stroke-width:2px
    style B fill:#bbdefb,stroke:#333,stroke-width:2px
    style C fill:#c8e6c9,stroke:#333,stroke-width:2px 
    style D fill:#c8e6c9,stroke:#333,stroke-width:2px  
    style E fill:#c8e6c9,stroke:#333,stroke-width:2px  
```

In the example above, the tests are in blue, and the answers (leaves) are in green!

> [!IMPORTANT]
> The choice of tests we make changes the structure of the tree and directly affects the algorithm’s efficiency! We will discuss this further in [3.splitting_criteria.md](./3.splitting_criteria.md)

## References:

[1] Müller, A. C., & Guido, S. (2016). Introduction to machine learning with Python: A guide for data scientists. O'Reilly Media.

[2] Bishop, C. M. (2006). Pattern recognition and machine learning. Springer.

# Portuguese Version

## Ideias introdutórias

A árvore de decisão é um modelo que serve tanto para classificação e regressão. [1] 

> [!NOTE]
> Lembrando que os problemas de regressão preveem números, como o preço de uma casa. Os de classificação são aqueles que preveem “rótulos” ou “categorias”, como se um email se encaixa na categoria “spam” ou “não spam”.
 
Como em uma árvore, temos raízes e folhas. No caso do modelo, a raíz é o nó superior e contém todo o conjunto de dados. As folhas são os nós finais e representam as respostas previstas pelo modelo.[1]

### Mas como saímos da raíz (conjunto de dados) e chegamos nas folhas (respostas finais)?

Basicamente, submetemos os dados à perguntas, as quais chamamos de “testes”. Já na raíz podemos ver o primeiro teste. Se a resposta for verdadeira, vamos ao nó da esquerda, se for falsa, vamos ao nó da direita.[1]

Repetiremos esse processo até chegarmos na folha!


#### Por exemplo:

Digamos que temos três frutas diferentes: **maçã**, **laranja** e **cereja**. A partir de características como cor e peso, podemos construir uma árvore para classificá-las.

```mermaid
flowchart TD
    A[A cor da fruta é vermelha?]
    A -- Sim --> B[O peso é maior que 75g?]
    A -- Não --> C[Laranja]
    B -- Sim --> D[Maçã]
    B -- Não --> E[Cereja]

    style A fill:#bbdefb,stroke:#333,stroke-width:2px
    style B fill:#bbdefb,stroke:#333,stroke-width:2px
    style C fill:#c8e6c9,stroke:#333,stroke-width:2px 
    style D fill:#c8e6c9,stroke:#333,stroke-width:2px  
    style E fill:#c8e6c9,stroke:#333,stroke-width:2px  
    
```
No caso acima, temos os testes em azul e as respostas (folhas) em verde!

> [!IMPORTANT]
> As escolhas de testes que fazemos mudam a estrutura da árvore e interferem diretamente na eficiência do algoritmo! Sobre isso, veremos em [3.splitting_criteria.md](./3.splitting_criteria.md)



## Referências:

[1] Müller, A. C., & Guido, S. (2016). Introduction to machine learning with Python: A guide for data scientists. O'Reilly Media.

[2] Bishop, C. M. (2006). Pattern recognition and machine learning. Springer.
