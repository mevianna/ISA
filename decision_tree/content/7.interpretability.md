# English version

## White Box vs Black Box

Models that are easy to interpret‚Äîthat is, whose prediction methods are clear‚Äîare called white box models. On the other hand, black box models do not provide transparency in how they operate. Although they are less interpretable, black box models often deliver higher prediction accuracy.

Decision trees are considered white box models due to their clear structure and the ease with which their prediction process can be understood. Below are some key characteristics of decision tree interpretability, as well as the importance of analyzing it. [1]

## Why is interpretability important in machine learning models?

When using a machine learning model, various issues can arise with the predictions, such as bias in the results, overfitting, or data errors. In this context, transparency about how the prediction was made becomes essential for identifying and correcting these problems.

## Visualization

Binary decision trees can be easily represented using two-dimensional diagrams. In the graph, it is possible to see each decision made at each node, the conditions that lead to different branches, and how each feature is organized within the structure. [2]

Below is a visual representation of a tree implemented in [1.decision_tree_classification](https://github.com/mevianna/ISA/blob/decision_tree/decision_tree/code/1.decision_tree_classification.md):

![Tree with pre-pruning](https://github.com/mevianna/ISA/blob/decision_tree/decision_tree/code/figures/arvore_pre_poda_2.png)  
*Image 1*

> [!NOTE]
> In the graph, you can observe all the possible paths the model may take based on the features of a new sample to be classified, until it reaches the terminal nodes‚Äîcalled leaf nodes‚Äîthat provide the final decision, in this case, benign or malignant.

## Reading as a Set of IF-THEN Rules and Decision Paths

The decision tree model can be easily understood as a set of *if-then* rules.  
This rule set follows a simple logic: *if* a condition is true, *then* make a prediction.

This concept is easier to understand by looking at *Image 1*. At the root node, the first condition is whether the *worst-radius* is less than or equal to 16.795. If the condition is true, the path continues to the left; if false, to the right.

Using these rules, it is possible to trace the path the tree followed to arrive at a given prediction, identifying which nodes were evaluated along the way to the leaf node responsible for the final classification.

## Feature Importance

Feature importance helps us understand how much each feature contributes to the prediction. Many input features may be irrelevant and could be excluded to reduce computational complexity and the amount of data required for future predictions.

The importance of a feature is calculated by summing the squared error reductions achieved at the nodes where that variable was used for splitting.

To calculate the importance of each predictor variable $$X$$, we use the following formula:

$$
\mathcal{I}^2_{\ell}(T) = \sum_{t=1}^{J-1} \hat{\iota}_t^2 \cdot I(v(t) = \ell)
$$

Where:

- $$\mathcal{I}^2_{\ell}(T)$$: measures the squared importance of variable $$\ell$$ in tree $$T$$;
- The sum is taken over the $$J - 1$$ internal nodes of the tree (i.e., all nodes that are not leaves);
- $$\hat{\iota}_t^2$$: represents how much the squared error decreases when the tree splits at node $$t$$;
- $$v(t)$$: is the variable used to split the data at node $$t$$;
- $$I(v(t) = \ell)$$: is an indicator function that equals 1 if variable $$\ell$$ was used at node $$t$$, and 0 otherwise.

[2]

## References

[1] A. Geron, *Hands-on Machine Learning with Scikit-Learn and TensorFlow*. Sebastopol, CA, USA: O‚ÄôReilly Media, 2017.  
[2] T. Hastie, R. Tibshirani, and J. Friedman, eds., *The Elements of Statistical Learning*. New York, NY, USA: Springer, 2014.

## üëæ **Contributors**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/197432407?v=4" width=115><br><sub>Beatriz Schuelter Tartare</sub>](https://github.com/beastartare) |
| :---: |

## **License**  
[![Licen√ßa MIT](https://img.shields.io/badge/Licen√ßa-MIT-blue.svg)](https://pt.wikipedia.org/wiki/Licen%C3%A7a_MIT)  
**Traslation:** Use, modify, and share at will! ‚úåÔ∏è


# Portuguese version

## Caixa Branca Vs Caixa Preta
  Os modelos que possuem facilidade de interpreta√ß√£o, ou seja, clareza em seu m√©todo de previs√£o, s√£o chamados de caixa branca. Por outro lado, modelos considerados caixa preta n√£o oferecem transpar√™ncia em seu funcionamento. Embora menos interpret√°veis, frequentemente apresentam maior acur√°cia nas previs√µes.
  
  As √°rvores de decis√£o s√£o consideradas um modelo de caixa branca devido √† sua estrutura clara e √† facilidade de entendimento do processo de previs√£o. Abaixo est√£o listadas algumas caracter√≠sticas fundamentais da interpretabilidade das √°rvores de decis√£o, al√©m da importancia de sua analise. [1]

## Qual a import√¢ncia da interpretabilidade nos modelos de aprendizado?
 Ao utilizar um modelo de aprendizado de m√°quina, √© poss√≠vel enfrentar diversos problemas relacionados √†s previs√µes, como vi√©s nos resultados, overfitting ou a presen√ßa de erros nos dados. Nesse contexto, a transpar√™ncia sobre como a previs√£o foi realizada torna-se essencial para a identifica√ß√£o e corre√ß√£o desses problemas.

## Visualiza√ß√£o 
 As √°rvores de decis√£o bin√°rias podem ser facilmente representados por graficos de duas dimens√µes. No gr√°fico, √© possivel visualizar cada decis√£o tomada em cada n√≥ com as condi√ß√µes que levam para diferentes ramos, al√©m de como cada atributo est√° organizado dentro a estrutura. [2]

 Abaixo √© poss√≠vel visualizar o grafico de uma √°rvore implementada em [1.decision_tree_classification](https://github.com/mevianna/ISA/blob/decision_tree/decision_tree/code/1.decision_tree_classification.md)

 ![√Årvore com pr√©-poda](https://github.com/mevianna/ISA/blob/decision_tree/decision_tree/code/figures/arvore_pre_poda_2.png)
 *Imagem 1*

> [!NOTE]
> No gr√°fico, √© poss√≠vel observar todos os trajetos potenciais que o modelo pode percorrer com base nas caracter√≠sticas da nova amostra a ser classificada, at√© atingir os n√≥s terminais ‚Äî denominados n√≥s folhas ‚Äî que apresentam a decis√£o final, neste caso, benigno ou maligno.

  
## Leitura como Conjunto de Regras (IF-THEN) e os caminhos de decis√£o
  O modelo baseado em √°rvores de decis√£o pode ser facilmente entendido pelo conjunto de regras *if-then*
Esse conjunto de regras √© baseado na l√≥gica: *se* uma condi√ß√£o for verdadeira *ent√£o* decis√£o da previs√£o.

Esse regra pode ser melhor entendida ao visualizar a *Imagem 1*. No n√≥ ra√≠z, a primeira condi√ß√£o √© o *worst-radius* ser menor ou igual a 16.795. Se a condi√ß√£o for verdadeira, percorre-se o caminho √† esquerda, se falsa o caminho √† direita.

Por meio dessas regras, √© poss√≠vel acompanhar o caminho que a √°rvore seguiu para chegar a uma determinada predi√ß√£o, identificando quais n√≥s foram avaliados ao longo do percurso at√© o n√≥ folha respons√°vel pela classifica√ß√£o final.

## Import√¢ncia das caracter√≠sticas
   A import√¢ncia das caracter√≠sticas √© utilizada para compreender a contribui√ß√£o de cada caracter√≠stica na previs√£o. Muitas das entradas s√£o irrelevantes e poderiam ser excluidas para assim diminuir a complexidade computacional, al√©m da quantidade de dados requeridos para as novas predi√ß√µes.

  O c√°lculo da importancia de caracteristica √© dada pela soma das redu√ß√µes do erro quadr√°tico obtidas nos n√≥s onde essa vari√°vel foi usada para dividir os dados.
  
Para calcular a import√¢ncia de cada vari√°vel preditora X utilizamos a seguinte f√≥rmula:
    
$$
\mathcal{I}^2_{\ell}(T) = \sum_{t=1}^{J-1} \hat{\iota}_t^2 \cdot I(v(t) = \ell)
$$

Onde:
- $$\mathcal{I}^2_{\ell}(T)$$: mede a import√¢ncia da vari√°vel $$\ell$$ ao quadrado, na √°rvore $$T$$;
- A soma √© feita sobre os $$J - 1$$ n√≥s internos da √°rvore (ou seja, todos os n√≥s que n√£o s√£o folhas);
- $$\hat{\iota}_t^2$$: representa quanto o erro quadr√°tico diminui ao dividir a √°rvore no n√≥ $$t$$;
- $$v(t)$$: √© a vari√°vel usada para fazer a divis√£o (split) no n√≥ $$t$$;
- $$I(v(t) = \ell)$$: √© uma fun√ß√£o que vale 1 se a vari√°vel $$\ell$$ foi usada no n√≥ $$t$$, e 0 se n√£o foi.

[2]
## Refer√™ncias
[1] A. Geron, Hands-on Machine Learning with Scikit-Learn and TensorFlow. Sebastopol, CA, USA: O‚ÄôReilly Media, 2017.

[2]	T. Hastie, R. Tibshirani, e J. Friedman, Orgs., The elements of statistical learning. Nova Iorque, NY, USA: Springer, 2014.

## üëæ **Contribuidores**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/197432407?v=4" width=115><br><sub>Beatriz Schuelter Tartare</sub>](https://github.com/beastartare) |
| :---: |

## **Licen√ßa**  
[![Licen√ßa MIT](https://img.shields.io/badge/Licen√ßa-MIT-blue.svg)](https://pt.wikipedia.org/wiki/Licen%C3%A7a_MIT)  
**Traslation:** Use, modifique e compartilhe √† vontade! ‚úåÔ∏è

