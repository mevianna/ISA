# English version

# Portuguese version

## Caixa Branca Vs Caixa Preta
  Os modelos que possuem facilidade de interpretação, ou seja, clareza em seu método de previsão, são chamados de caixa branca. Por outro lado, modelos considerados caixa preta não oferecem transparência em seu funcionamento. Embora menos interpretáveis, frequentemente apresentam maior acurácia nas previsões.
  
  As árvores de decisão são consideradas um modelo de caixa branca devido à sua estrutura clara e à facilidade de entendimento do processo de previsão. Abaixo estão listadas algumas características fundamentais da interpretabilidade das árvores de decisão, além da importancia de sua analise. [1]

## Qual a importância da interpretabilidade nos modelos de aprendizado?
 Ao utilizar um modelo de aprendizado de máquina, é possível enfrentar diversos problemas relacionados às previsões, como viés nos resultados, overfitting ou a presença de erros nos dados. Nesse contexto, a transparência sobre como a previsão foi realizada torna-se essencial para a identificação e correção desses problemas.

## Visualização 
 As árvores de decisão binárias podem ser facilmente representados por graficos de duas dimensões. No gráfico, é possivel visualizar cada decisão tomada em cada nó com as condições que levam para diferentes ramos, além de como cada atributo está organizado dentro a estrutura. [2]

 Abaixo é possível visualizar o grafico de uma árvore implementada em [1.decision_tree_classification](https://github.com/mevianna/ISA/blob/decision_tree/decision_tree/code/1.decision_tree_classification.md)

 ![Árvore com pré-poda](https://github.com/mevianna/ISA/blob/decision_tree/decision_tree/code/figures/arvore_pre_poda_2.png)
 *Imagem 1*

> [!NOTE]
> No gráfico, é possível observar todos os trajetos potenciais que o modelo pode percorrer com base nas características da nova amostra a ser classificada, até atingir os nós terminais — denominados nós folhas — que apresentam a decisão final, neste caso, benigno ou maligno.

  
## Leitura como Conjunto de Regras (IF-THEN) e os caminhos de decisão
  O modelo baseado em árvores de decisão pode ser facilmente entendido pelo conjunto de regras *if-then*
Esse conjunto de regras é baseado na lógica: *se* uma condição for verdadeira *então* decisão da previsão.

Esse regra pode ser melhor entendida ao visualizar a *Imagem 1*. No nó raíz, a primeira condição é o *worst-radius* ser menor ou igual a 16.795. Se a condição for verdadeira, percorre-se o caminho à esquerda, se falsa o caminho à direita.

Por meio dessas regras, é possível acompanhar o caminho que a árvore seguiu para chegar a uma determinada predição, identificando quais nós foram avaliados ao longo do percurso até o nó folha responsável pela classificação final.

## Importância das características
   A importância das características é utilizada para compreender a contribuição de cada característica na previsão. Muitas das entradas são irrelevantes e poderiam ser excluidas para assim diminuir a complexidade computacional, além da quantidade de dados requeridos para as novas predições.

  O cálculo da importancia de caracteristica é dada pela soma das reduções do erro quadrático obtidas nos nós onde essa variável foi usada para dividir os dados.
  
Para calcular a importância de cada variável preditora X utilizamos a seguinte fórmula:
    
$$
\mathcal{I}^2_{\ell}(T) = \sum_{t=1}^{J-1} \hat{\iota}_t^2 \cdot I(v(t) = \ell)
$$

Onde:
- $$\( \mathcal{I}^2_{\ell}(T) \) $$: importância relativa ao quadrado da variável $$\( \ell \)$$ na árvore $$\( T \)$$;
- A soma ocorre sobre os $$\( J - 1 \)$$ nós internos da árvore;
- $$\( \hat{\iota}_t^2 \)$$: é a redução do erro quadrático estimada ao fazer o split no nó $$\( t \)$$;
- $$\( v(t) \)$$: representa a variável usada na divisão do nó $$\( t \)$$;
- $$\( I(v(t) = \ell) \)$$: é a função indicadora que vale 1 quando a variável $$\( \ell \)$$ foi usada no nó $$\( t \)$$, e 0 caso contrário.
[2]
## Referências
[1] A. Geron, Hands-on Machine Learning with Scikit-Learn and TensorFlow. Sebastopol, CA, USA: O’Reilly Media, 2017.

[2]	T. Hastie, R. Tibshirani, e J. Friedman, Orgs., The elements of statistical learning. Nova Iorque, NY, USA: Springer, 2014.



