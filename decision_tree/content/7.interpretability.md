# English version

## White Box vs Black Box

Models that are easy to interpret—that is, whose prediction methods are clear—are called white box models. On the other hand, black box models do not provide transparency in how they operate. Although they are less interpretable, black box models often deliver higher prediction accuracy.

Decision trees are considered white box models due to their clear structure and the ease with which their prediction process can be understood. Below are some key characteristics of decision tree interpretability, as well as the importance of analyzing it. [1]

## Why is interpretability important in machine learning models?

When using a machine learning model, various issues can arise with the predictions, such as bias in the results, overfitting, or data errors. In this context, transparency about how the prediction was made becomes essential for identifying and correcting these problems.

## Visualization

Binary decision trees can be easily represented using two-dimensional diagrams. In the graph, it is possible to see each decision made at each node, the conditions that lead to different branches, and how each feature is organized within the structure. [2]

Below is a visual representation of a tree implemented in [1.decision_tree_classification](https://github.com/mevianna/ISA/blob/decision_tree/decision_tree/code/1.decision_tree_classification.md):

![Tree with pre-pruning](https://github.com/mevianna/ISA/blob/decision_tree/decision_tree/code/figures/arvore_pre_poda_2.png)  
*Image 1*

> [!NOTE]
> In the graph, you can observe all the possible paths the model may take based on the features of a new sample to be classified, until it reaches the terminal nodes—called leaf nodes—that provide the final decision, in this case, benign or malignant.

## Reading as a Set of IF-THEN Rules and Decision Paths

The decision tree model can be easily understood as a set of *if-then* rules.  
This rule set follows a simple logic: *if* a condition is true, *then* make a prediction.

This concept is easier to understand by looking at *Image 1*. At the root node, the first condition is whether the *worst-radius* is less than or equal to 16.795. If the condition is true, the path continues to the left; if false, to the right.

Using these rules, it is possible to trace the path the tree followed to arrive at a given prediction, identifying which nodes were evaluated along the way to the leaf node responsible for the final classification.

## Feature Importance

Feature importance helps us understand how much each feature contributes to the prediction. Many input features may be irrelevant and could be excluded to reduce computational complexity and the amount of data required for future predictions.

The importance of a feature is calculated by summing the squared error reductions achieved at the nodes where that variable was used for splitting.

To calculate the importance of each predictor variable $$X$$, we use the following formula:

$$
\mathcal{I}^2_{\ell}(T) = \sum_{t=1}^{J-1} \hat{\iota}_t^2 \cdot I(v(t) = \ell)
$$

Where:

- $$\mathcal{I}^2_{\ell}(T)$$: measures the squared importance of variable $$\ell$$ in tree $$T$$;
- The sum is taken over the $$J - 1$$ internal nodes of the tree (i.e., all nodes that are not leaves);
- $$\hat{\iota}_t^2$$: represents how much the squared error decreases when the tree splits at node $$t$$;
- $$v(t)$$: is the variable used to split the data at node $$t$$;
- $$I(v(t) = \ell)$$: is an indicator function that equals 1 if variable $$\ell$$ was used at node $$t$$, and 0 otherwise.

[2]

## References

[1] A. Geron, *Hands-on Machine Learning with Scikit-Learn and TensorFlow*. Sebastopol, CA, USA: O’Reilly Media, 2017.  
[2] T. Hastie, R. Tibshirani, and J. Friedman, eds., *The Elements of Statistical Learning*. New York, NY, USA: Springer, 2014.


# Portuguese version

## Caixa Branca Vs Caixa Preta
  Os modelos que possuem facilidade de interpretação, ou seja, clareza em seu método de previsão, são chamados de caixa branca. Por outro lado, modelos considerados caixa preta não oferecem transparência em seu funcionamento. Embora menos interpretáveis, frequentemente apresentam maior acurácia nas previsões.
  
  As árvores de decisão são consideradas um modelo de caixa branca devido à sua estrutura clara e à facilidade de entendimento do processo de previsão. Abaixo estão listadas algumas características fundamentais da interpretabilidade das árvores de decisão, além da importancia de sua analise. [1]

## Qual a importância da interpretabilidade nos modelos de aprendizado?
 Ao utilizar um modelo de aprendizado de máquina, é possível enfrentar diversos problemas relacionados às previsões, como viés nos resultados, overfitting ou a presença de erros nos dados. Nesse contexto, a transparência sobre como a previsão foi realizada torna-se essencial para a identificação e correção desses problemas.

## Visualização 
 As árvores de decisão binárias podem ser facilmente representados por graficos de duas dimensões. No gráfico, é possivel visualizar cada decisão tomada em cada nó com as condições que levam para diferentes ramos, além de como cada atributo está organizado dentro a estrutura. [2]

 Abaixo é possível visualizar o grafico de uma árvore implementada em [1.decision_tree_classification](https://github.com/mevianna/ISA/blob/decision_tree/decision_tree/code/1.decision_tree_classification.md)

 ![Árvore com pré-poda](https://github.com/mevianna/ISA/blob/decision_tree/decision_tree/code/figures/arvore_pre_poda_2.png)
 *Imagem 1*

> [!NOTE]
> No gráfico, é possível observar todos os trajetos potenciais que o modelo pode percorrer com base nas características da nova amostra a ser classificada, até atingir os nós terminais — denominados nós folhas — que apresentam a decisão final, neste caso, benigno ou maligno.

  
## Leitura como Conjunto de Regras (IF-THEN) e os caminhos de decisão
  O modelo baseado em árvores de decisão pode ser facilmente entendido pelo conjunto de regras *if-then*
Esse conjunto de regras é baseado na lógica: *se* uma condição for verdadeira *então* decisão da previsão.

Esse regra pode ser melhor entendida ao visualizar a *Imagem 1*. No nó raíz, a primeira condição é o *worst-radius* ser menor ou igual a 16.795. Se a condição for verdadeira, percorre-se o caminho à esquerda, se falsa o caminho à direita.

Por meio dessas regras, é possível acompanhar o caminho que a árvore seguiu para chegar a uma determinada predição, identificando quais nós foram avaliados ao longo do percurso até o nó folha responsável pela classificação final.

## Importância das características
   A importância das características é utilizada para compreender a contribuição de cada característica na previsão. Muitas das entradas são irrelevantes e poderiam ser excluidas para assim diminuir a complexidade computacional, além da quantidade de dados requeridos para as novas predições.

  O cálculo da importancia de caracteristica é dada pela soma das reduções do erro quadrático obtidas nos nós onde essa variável foi usada para dividir os dados.
  
Para calcular a importância de cada variável preditora X utilizamos a seguinte fórmula:
    
$$
\mathcal{I}^2_{\ell}(T) = \sum_{t=1}^{J-1} \hat{\iota}_t^2 \cdot I(v(t) = \ell)
$$

Onde:
- $$\mathcal{I}^2_{\ell}(T)$$: mede a importância da variável $$\ell$$ ao quadrado, na árvore $$T$$;
- A soma é feita sobre os $$J - 1$$ nós internos da árvore (ou seja, todos os nós que não são folhas);
- $$\hat{\iota}_t^2$$: representa quanto o erro quadrático diminui ao dividir a árvore no nó $$t$$;
- $$v(t)$$: é a variável usada para fazer a divisão (split) no nó $$t$$;
- $$I(v(t) = \ell)$$: é uma função que vale 1 se a variável $$\ell$$ foi usada no nó $$t$$, e 0 se não foi.

[2]
## Referências
[1] A. Geron, Hands-on Machine Learning with Scikit-Learn and TensorFlow. Sebastopol, CA, USA: O’Reilly Media, 2017.

[2]	T. Hastie, R. Tibshirani, e J. Friedman, Orgs., The elements of statistical learning. Nova Iorque, NY, USA: Springer, 2014.



