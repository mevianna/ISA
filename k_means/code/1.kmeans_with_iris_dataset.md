# English Version
In this section, the execution of the K-Means Clustering algorithm using the *Python* programming language will be presented and demonstrated. The implementation that will be explored follows the same structure described in: [6.How the algorithm is executed?](https://github.com/mevianna/ISA/tree/k_means/k_means/content/6.how_the_algorithm_is_executed.md).

***

# Portuguese Version
Nessa seção, será apresentada e demonstrada a execução do algoritmo K-Means Clustering utilizando a linguagem de programação *Python*. A implementação que será explorada segue a mesma estrutura descrita em: [6.Como o algoritmo é executado?](https://github.com/mevianna/ISA/tree/k_means/k_means/content/6.how_the_algorithm_is_executed.md). Na execução abordada nesse arquivo, foi utilizado um Dataset já existente.

***

## Detalhes do Dataset
Para executar o K-Means, foi utilizado o dataset "Iris", disponível em: [Iris Dataset - UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/53/iris). Esse Dataset é um dos mais utilizados para estudos de Machine Learning, possuindo 150 linhas de dados, divididos em 3 classes, as quais cada uma representa um tipo de flor Iris, e 5 colunas, sendo elas: sepal_length, sepal_width, petal_length, petal_width e species. As quatro primeiras colunas representam caracteristícas morfológicas das flores, enquanto a última coluna ("species") corrresponde à classe da flor, isto é, o rótulo verdadeiro (target). Cabe ressaltar que esse dataset não possui valores nulos.

>[!NOTE]
> Como o "target" é o rótulo verdadeiro, ele não é utilizado no K-Means, uma vez que o algoritmo é não-supervisionado, ou seja, ele agrupa os dados sem conhecer suas reais classificações.

***

## Código:

### Importação de bibliotecas e funções:

```python 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
```

No trecho de código acima, são importadas bibliotecas e funções que serão utilizadas ao longo do código, sendo elas:

* ```import pandas as pd```: Importa a biblioteca "pandas", utilizada para manipulação e análise de dados, nomeada como "pd";
* ```import numpy as np```: Importa a biblioteca "numpy", utilizada para operações matemáticas e matriciais, nomeada como "np";
* ```import matplotlib.pyplot as plt```: Importa o módulo "pyplot" da biblioteca "matplotlib", utilizada para visualização gráfica, nomeada como "plt";
* ```from sklearn.cluster import KMeans```: Importa a classe "KMeans" do módulo de agrupamento do "scikit-learn", que implementa o algoritmo de clusterização K-Means.
* ```from sklearn.preprocessing import StandardScaler```: Importa a classe "StandardScaler" do módulo de agrupamento do "scikit-learn", que realiza a normalização dos dados o algoritmo de clusterização K-Means.
* ```from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score```: Importa três métricas de validação do módulo de agrupamento do "scikit-learn".

### Importação do Dataset
```python
url = "https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv"
df = pd.read_csv(url)
```

No trecho de código acima, o Dataset é lido a partir de um link disponível na internet. Ele é definido, então, como "df" para o resto do código.

> Sugestão: para obter caracteristícas do Dataset, como o nome das colunas, a quantidade de linhas e se há espaços em branco, execute: 
> ```python 
> print(df.head())
> print(df.shape)
> df.isnull().values.any()
> ```

### Padronização dos dados
A normalização (padronização) é um processo de transformação dos dados para que fiquem em uma mesma escala, sem distorcer as relações entre eles. Isso é necessário pois os atributos podem possuir escalas diferente; por exemplo, enquanto a idade pode variar entre 0 e 100, o salário pode estar na casa dos milhares.
Se não normalizados, atributos com maiores valores podem dominar algoritmos baseados em distância, como o K-Means. Para resolver isso, utiliza-se uma função que padroniza os dados, transformando-os de forma que tenham média 0 e desvio padrão 1, tornando todos os atributos igualmente relevantes para os cálculos. No scikit-learn, isso é feito com a classe StandardScaler, conforme visto abaixo:

```python 
X = df[['sepal_length',  'sepal_width',  'petal_length',  'petal_width']]
scaler = StandardScaler()
X_padronizado = scaler.fit_transform(X)
```

Na primeira linha, são separadas apenas as linhas "feature" do dataset, ou seja, os atributos utilizados para o agrupamento. Por ventura, nesse dataset, todas as colunas são numéricas, então não é preciso nenhuma manipulação em relação a isso. Assim, "X" é uma matriz com as 4 primeiras colunas do dataset e todas as linhas do conjunto de dados.

A segunda linha cria um objeto do tipo StandardScaler, que é utilizado para padronizar os dados. Assim, essa padronização é aplicada na nova tabela na terceira linha, em que "X_padronizado" é a nova tabela, com as 4 colunas padronizadas, isto é, com valores com desvio padrão 1 e média 0.

### Plotagem dos dados sem agrupamentos
No conjunto de dados, há 4 colunas de atributos, isto é, 4 dimensões. Como é impossível representar dados nessa condição, nesse exemplo, utiliza-se apenas duas dimensões. Dessa maneira, optou-se pelos atributos "sepal_length" e "sepal_width", mas qualquer outro par de atributos poderia ser utilizado. O trecho de código que permite a plotagem do gráfico está logo abaixo.

```python
plt.figure(figsize=(6, 5))
plt.scatter(X_padronizado[:, 0], X_padronizado[:, 1], c='hotpink')
plt.xlabel("Sepal length")
plt.ylabel("Sepal width")
plt.title("Dados Iris sem agrupamento")
plt.show()
``` 

A primeira linha, ```python plt.figure(figsize=(6, 5))```, cria a figura, a qual será o gráfico, definindo seu tamanho. Em seguida, ```python plt.scatter(X_padronizado[:, 0], X_padronizado[:, 1], c='hotpink')```, gera um gráfico de dispersão, o qual plota pontos numa figura 2D. Nessa função,
* O primeiro argumento, ```python X_padronizado[:, 0]```, fornece os dados do eixo X. Ele seleciona todas as linhas da coluna 0 (primeira coluna) da matriz X_padronizada.
* O segundo argumento, ```python X_padronizado[:, 1]```, faz o mesmo para o eixo Y, escolhendo todas as linhas da segunda coluna (coluna 1) da matriz X_padronizada. 
* O último argumento, ```python c='hotpink'```, determina a cor dos pontos como "hotpink".

As 2 linhas seguintes determinam rõtulos do gráfico, sendo, em ordem, rõtulo do eixo X e rótulo do eixo Y. A linha posterior, determina o título do grãfico. 

Por fim, a última linha, ```python plt.show()``` exibe o gráfico formado, o qual pode ser visto abaixo.  

<div align="center">
<img src= "..\img\dataset1_without_clusters.png" alt="Plotagem dos dados sem agrupamento" width="400">
</div>

### Como definir o número de clusters
Como visto anteriormente, em [4.Como escolher o número de clusters?](https://github.com/mevianna/ISA/tree/k_means/k_means/content/3.how_to_choose_the_number_of_clusters.md), existem alguns métodos para determinar o número de clusters. Nesse caso, será visto o método do cotovelo e o método da silhueta.

### Método do cotovelo
Uma das formas de determinar o número de clusters, é pelo método do cotovelo, conforme já abordado. Para isso, é executado o seguinte código:

```python
inercias = []
valores_k = range(1, 11)

for k in valores_k:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_padronizado)
    inercias.append(kmeans.inertia_)

plt.plot(valores_k, inercias, 'mo-')
plt.xlabel("Número de clusters (K)")
plt.ylabel("Inércia")
plt.title("Método do Cotovelo")
plt.show()
```

Na primeira linha, ```python inercias = []```, é criada uma lista vazia que irá armazenar os valores da inércia para cada valor de k testado. A linha seguinte, ```python valores_k = range(1, 11)```, gera uma sequência de 1 a 10, que são os valores de k a serem testados.

A terceira linha é um loop *for*, o qual percorre os valores da sequência gerada com a variável k. A linha posterior, ```python kmeans = KMeans(n_clusters=k, random_state=42)```, cria um objeto do algoritmo KMeans, com o número de clusters igual ao valor de k, e com a semente aleatória, isto é, escolha de centróides iniciais de forma aleatória.

A linha seguinte, ```python kmeans.fit(X_padronizado)```, treina o objeto KMeans criado com os dados da matriz X_padronizada. A linha seguinte, ```python inercias.append(kmeans.inertia_)```, adiciona na lista de inércias a inércia da execução do KMeans, atributo do objeto KMeans, ou seja, calculado pela própria biblioteca.

Após todos os testes com os valores da sequência, a linha ```python plt.plot(valores_k, inercias, 'mo-')``` cria o gráfico de linha para o método do cotovelo, sendo que o primeiro argumento é o valor do eixo X, o segundo, o valor do eixo Y, e o terceiro, uma formatação, em que:
* "m": define a cor da linha como magenta;
* "o": adiciona marcadores em formato de circulo a cada ponto de dados no gráfico;
* "-": traça uma linha entre os pontos do gráfico.

As linhas posteriores, apenas rotulam o gráfico e mostram ele, que pode ser visualizado logo abaixo.

<div align="center">
<img src= "..\img\elbow_method_dataset1.png" alt="Plotagem do método do cotovelo" width="400">
</div>

Analisando o gráfico, é possível ver que a "dobra" do cotovelo está mais nitída em **k = 3**. Assim, o melhor valor de k, segundo este método, é 3.

### Método da silhueta
Outra forma de visualizar o valor de k, é através do método da silhueta. Para tal, executamos o seguinte código:

```python
silhueta = []
valores_k = range(2, 11)

for k in valores_k:
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X_padronizado)
    score = silhouette_score(X_padronizado, labels)
    silhueta.append(score)

plt.plot(valores_k, silhueta, 'mo-')
plt.xlabel("Número de clusters (k)")
plt.ylabel("Silhueta média")
plt.title("Método da Silhueta para escolha de k")
plt.grid(True)
plt.show()
```

<div align="center">
<img src= "..\img\sillhoutte_method_dataset1.png" alt="Plotagem do método da silhueta" width="400">
</div>

### Definição do número de clusters

### Plotagem do gráfico com os agrupamentos

### Métricas de validação
