## English version

## Portuguese version

## Conceitos fundamentais

#### Dados Não Rotulados
O K-means opera em conjuntos de dados onde não há informações pré-existentes sobre a qual "classe" ou "grupo" cada ponto pertence. O objetivo do algoritmo é descobrir essa estrutura inerente nos dados.

#### Pontos de Dados (Data Points)
Cada observação individual no seu conjunto de dados. Pode ser um único número (em uma dimensão), um par de números (em duas dimensões, como em um gráfico x-y), ou uma sequência de números (em múltiplas dimensões, representando diferentes características).

#### Clusters
Os grupos que o algoritmo K-means tenta identificar nos dados. O objetivo é que os pontos dentro do mesmo cluster sejam semelhantes entre si e diferentes dos pontos em outros clusters.

#### Centróides
São os pontos centrais de cada cluster. Inicialmente, eles podem ser escolhidos aleatoriamente ou por algum método heurístico. Durante o processo do K-means, os centróides são recalculados iterativamente como a média de todos os pontos atribuídos àquele cluster.

#### Atribuição de Pontos a Clusters
Cada ponto de dados é atribuído ao cluster cujo centróide está mais próximo dele, com base em alguma medida de distância.

## Inércia (Within-Cluster Sum of Squares - WCSS)
A Inércia é uma métrica fundamental que quantifica a soma das distâncias quadráticas de cada ponto dentro de um cluster até o seu respectivo centróide. O principal objetivo do algoritmo é minimizar essa inércia; portanto, essa métrica mede quão bem um conjunto de dados foi agrupado com base em métricas de distância. Sendo assim, a inércia é calculada medindo a distância entre um ponto de dado e seu centróide, elevando essa distância ao quadrado e somando esses quadrados para cada ponto do agrupamento. A soma é a representação da distância intra-agrupamento, ou seja, quanto menor a soma, melhor, pois isso significa que os pontos dentro dos agrupamentos são mais compactos ou semelhantes. Ademais, é importante notar que a inércia sempre diminui com o aumento do número de clusters e assume que os clusters são convexos e isotrópicos.

## Índice de Dunn
O índice de Dunn representa a relação entre a menor distância entre clusters e a maior distância dentro de um cluster. Clusters com uma alta distância entre eles indicam melhor qualidade, pois isso significa que os clusters são o mais diferentes possível uns dos outros.

## Cálculo da distância
O cálculo da distância entre os pontos de dados e os centróides é um passo crucial para o K-means, pois determina a qual cluster cada ponto será atribuído. Logo, a escolha da métrica de distância influencia diretamente a forma e a estrutura dos clusters resultantes.

### Métrica de Distância Euclidiana
A distância euclidiana é a forma mais comum de medir a distância entre dois pontos. Para calcular a distância euclidiana entre dois pontos, $p$ e $q$, num espaço $n$-dimensional, onde $p$ é definido como $(p_1, p_2, ..., p_n)$ e $q$ como $(q_1, q_2, ..., q_n)$, usamos a seguinte fórmula:

$$d(p, q) = \sqrt{\sum_{i=1}^{n} (q_i - p_i)^2}$$

Nesta fórmula, o símbolo $\sum$ indica o somatório, $n$ é o número de dimensões do espaço e $p_i$ e $q_i$ são as coordenadas dos pontos $p$ e $q$, respectivamente. O cálculo envolve os seguintes passos: primeiro, calcula-se a diferença entre as coordenadas dos dois pontos em cada dimensão; depois, eleva-se ao quadrado cada uma dessas diferenças; em seguida, somam-se todos os valores resultantes; e, finalmente, calcula-se a raiz quadrada desta soma, obtendo-se a distância euclidiana entre os dois pontos.

**Exemplo:**

$$\sqrt{(4 - 1)^2 + (6 - 2)^2} = \sqrt{3^2 + 4^2} = \sqrt{9 + 16} = \sqrt{25} = 5$$

<div align="center">
  <img src="https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/88/64/k-means-clustering-graph.png" alt="k-means-clustering-graph" width="800">
</div>

## Seleção do Número Ideal de Clusters (Método do Cotovelo)
A inércia auxilia na determinação do número ideal de clusters ($k$). Ao plotar a inércia para diferentes valores de $k$, espera-se observar uma queda na inércia à medida que $k$ aumenta. Em algum ponto, essa queda se torna menos significativa, formando um "cotovelo".
A partir disso, surgiu o método do cotovelo, uma maneira gráfica de determinar o número de agrupamentos. Ele mede a distância euclidiana entre cada ponto de dado e seu centróide e escolhe o número de agrupamentos com base no ponto em que a mudança na "soma dos quadrados dentro do agrupamento" se estabiliza. Esse valor representa a variância total dentro de cada agrupamento, que é plotada contra o número de agrupamentos.
O primeiro passo do método do cotovelo é calcular o WCSS para cada número de clusters ($k$). Em seguida, o valor de WCSS é plotado no eixo y e o número de agrupamentos no eixo x. À medida que o número de agrupamentos aumenta, os pontos do gráfico devem formar um padrão consistente. A partir desse padrão, obtém-se uma faixa para o número ótimo de agrupamentos. Ao decidir o número de agrupamentos, é importante considerar os custos computacionais. Quanto maior o número de agrupamentos, mais poder de processamento é necessário, especialmente com conjuntos de dados grandes.

<div align="center">
  <img src="https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/88/64/k-means-clustering-graph.png" alt="k-means-clustering-graph" width="800">
</div>

## Seleção do Número Ideal de Clusters (Método da Silhueta)
No método da Silhueta, é analisado um coeficiente resultante do cálculo da distância entre os centróides, levando em consideração o agrupamento dos dados. Sendo assim, o gráfico em barras horizontais mostra, para cada cluster, o valor do coeficiente dos dados mais próximos aos mais distantes, formando uma "silhueta".
O coeficiente fica entre o intervalo de -1 a +1, em que "+1" representa a maior distância entre os clusters, "0" seria a aproximação do ponto de decisão e um valor negativo significa que, possivelmente, os dados estão agrupados de forma inadequada.

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*SqMaMMzbiS9h4Jj_47akug.png" alt="Gráfico de Silhueta com 2 Clusters" width="800">
</div>

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*vzNSANw8qh-2GG9INGzGLQ.png" alt="Gráfico de Silhueta com 3 Clusters" width="800">
</div>

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*tzeZg6vMMTNpevs4Wdfo-A.png" alt="Gráfico de Silhueta com 4 Clusters" width="800">
</div>

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*7F_ujfWnh2lfbGspaFKM1g.png" alt="Gráfico de Silhueta com 5 Clusters" width="800">
</div>

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Eg3O6kcJiF7vAWY9RieLfw.png" alt="Gráfico de Silhueta com 6 Clusters" width="800">
</div>

Os `n_clusters` 3, 5 e 6 possuem clusters com coeficiente abaixo do valor médio (tracejado em vermelho), ou seja, são negativos, portanto devem ser descartados da análise, sobrando `n_clusters` 2 e 4. O primeiro apresenta maior diferença entre seus clusters, enquanto o 4 possui tamanhos similares, sugerindo ser a melhor escolha para a quantidade de clusters.

## Referências
https://www.datacamp.com/tutorial/k-means-clustering-python
https://www.ibm.com/br-pt/think/topics/k-means-clustering#:~:text=O%20agrupamento%20K%2Dmeans%20%C3%A9,usados%20em%20aprendizado%20de%20m%C3%A1quina
https://medium.com/cwi-software/entendendo-clusters-e-k-means-56b79352b452
https://www.datacamp.com/pt/tutorial/euclidean-distance
