## English Version


## Portuguese Version

## Como Escolher os centroides Iniciais?

A escolha dos **centroides iniciais** no algoritmo K-means é um passo fundamental que pode impactar fortemente o resultado final. Uma má escolha pode levar a mínimos locais ou lentidão na convergência, por isso, existem métodos para realizar a inicialização de centroides.

### Pontos de Dados Aleatórios

Nesse método, $k$ **pontos de dados aleatórios** são selecionados do conjunto de dados e usados como centroides iniciais. Embora cada instância de dados no conjunto deva ser enumerada e registrar o valor mínimo/máximo de cada atributo, essa abordagem é considerada muito volátil, pois pode levar a um cenário em que os centroides selecionados não estão bem posicionados.

<div align="center">
<img src="https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-2-1.jpg?resize=1020%2C534&ssl=1" alt="k-means-clustering-graph" width="800">
  <p align="center"><b>Pontos de dados definidos em locais aleatórios e definidos como centroides dos clusters</b></p>
</div>

O gráfico acima ilustra que o centroide representa o centro de um cluster. Inicialmente, o centro desses pontos de dados é desconhecido. Portanto, selecionamos pontos de dados aleatórios e os definimos como centroides para cada cluster. Neste exemplo, há 3 centroides no conjunto de dados.

<div align="center">
<img src="https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-3.jpg?resize=1020%2C534&ssl=1" alt="k-means-clustering-graph" width="800">
  <p align="center"><b>Atribuição de ponto de dado ao centroide de cluster mais próximo.</b></p>
</div>

Com os centroides inicializados, os pontos de dados $X_n$ são atribuídos ao seu centroide de cluster mais próximo $C$. Ademais, nesta etapa, torna-se necessário calcular a distância entre o ponto de dado $X$ e o centroide $C$.

$$d(p, q) = \sqrt{\sum_{i=1}^{n} (q_i - p_i)^2}$$

Posteriormente, cada ponto de dado é atribuído ao cluster cujo centroide apresente a menor distância.

<div align="center">
<img src="https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-4.jpg?resize=1020%2C534&ssl=1" alt="k-means-clustering-graph" width="800">
</div>

Em seguida, os centroides são recalculados pela média de todos os pontos de dados de cada *cluster*, conforme a fórmula:

$$C_i = \frac{1}{|N_i|} \sum x_i$$

Onde:

* **$C_i$**: é o centroide do grupo $i$, ou seja, o "centro" do agrupamento - um vetor médio que representa todos os pontos pertencentes a esse grupo.
* **$N_i$**: é o conjunto de pontos atribuídos ao grupo $i$.
* **$\sum x_i$**: é a soma de todos os vetores $x_i$, que pertencem ao grupo $N_i$.

<div align="center">
<img src="https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-5.jpg?resize=1020%2C534&ssl=1" width="800">
</div>

Este processo é repetido até que o número de centroides ideais seja alcançado e as atribuições dos pontos de dados aos *clusters* estejam corretas (ou seja, não haja mais mudanças significativas nas atribuições ou nos centroides).

<div align="center">
<img src="https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-6.jpg?resize=1020%2C534&ssl=1" width="800">
  <p align="center"><b>Ciclo de atribuição finalizado.</b></p>
</div>

## Fragmentação Ingênua

A fragmentação ingênua é uma estratégia simples para dividir dados em grupos (*clusters*) sem considerar a estrutura ou distribuição real dos dados. Por essa razão de não considerar a densidade, distância entre pontos ou variabilidade, é utilizada em contextos como: inicialização de centroides antes de aplicar o K-Means++, divisão de dados para teste e agrupamentos artificiais em simulações. Assim, utiliza-se o valor da soma composta de todos os atributos para uma instância ou linha específica em um conjunto de dados, ou seja, a ideia é calcular o valor composto e usá-lo para ordenar as instâncias dos dados.

<div align="center">
<img src="https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/K-Means-Clustering_12.png?ssl=1" width="800">
</div>

**Passo 1:**
Some os atributos de cada instância e adicione a coluna de resultado no início do conjunto de dados.

**Passo 2:**
Ordene as instâncias do conjunto de dados pela nova coluna de soma, em ordem crescente.

**Passo 3:**
Divida o conjunto de dados horizontalmente em $k$ partes de tamanho igual, ou fragmentos.

Finalizando, os atributos de cada fragmento são somados e suas médias calculadas. Os valores médios dos atributos de cada fragmento serão identificados como o conjunto de centroides que pode ser usado para inicialização.

<div align="center">
<img src="https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/K-Means-Clustering_3.png?ssl=1" width="800">
</div>

**Passo 4:**
Para cada fragmento, calcule a média das colunas de atributos; os valores médios se tornam os valores correspondentes dos atributos do novo centroide.

Por ocorrer em tempo linear, ou seja, o tempo que o algoritmo leva para ser executado cresce proporcionalmente à quantidade de dados de entrada, sendo, portanto, muito melhor que o da inicialização aleatória. Entretanto, ela apresenta os mesmos problemas de ter a chance de apresentar resultados inconsistentes.

## K-Means++

O K-Means++ é uma variação do algoritmo K-means que otimiza a escolha dos centroides iniciais dos grupos, além de melhorar a qualidade da atribuição final dos agrupamentos.

O primeiro passo dessa inicialização é escolher de forma aleatória um centroide a partir do conjunto de dados. Para os próximos centroides, calcula-se a distância de cada ponto de dado até o centroide mais próximo já escolhido. Com isso, o próximo é escolhido a partir da probabilidade proporcional à distância de um ponto até o centroide mais próximo, logo quanto maior essa distância, maior a chance de o ponto ser escolhido.
Apesar de sua semelhança com o método da escolha aleatória, o K-Means++ é uma escolha aleatória com inteligência, por utilizar a distância entre os pontos para guiar essa aleatoriedade.

**Passos:**
**Passo 1:** Escolha aleatoriamente o primeiro centroide ($C_1$).
**Passo 2:** Calcule a distância entre todos os pontos de dados e o centroide selecionado.

$$D_i = \max_{(j:1 \rightarrow k)} \|x_i - c_j\|^2$$

- $D_i$: é a maior distância euclidiana ao quadrado entre o ponto de dado $x_i$ e qualquer um dos centroides $c_j$ já escolhidos.
- $x_i$: o ponto do conjunto de dados.
- $c_j$: um centroide já escolhido.
- $\|x_i - c_j\|^2$: a distância euclidiana ao quadrado entre $x_i$ e $c_j$.
- max: indica o valor máximo entre um conjunto de valores.
- $(j:1 \rightarrow k)$: Refere-se à iteração sobre os $k$ centroides já selecionados. Em um algoritmo de agrupamento como o K-Means++, $j$ representa um centroide já escolhido, e $k$ é o número de centroides que já foram inicializados até o momento.

**Passo 3:** Inicialize o ponto de dado $x$ como novo centroide.
**Passo 4:** Repita os passos 2 e 3 até que todos os clusters sejam encontrados.

<div align="center">
<img src="https://media.geeksforgeeks.org/wp-content/uploads/20190812011808/Screenshot-2019-08-12-at-1.13.15-AM.png" width="800">
  <p align="center"><b>Agrupamento ruim.</b></p>
</div>

<div align="center">
<img src="https://media.geeksforgeeks.org/wp-content/uploads/20190812011831/Screenshot-2019-08-12-at-1.09.42-AM.png" width="800">
  <p align="center"><b>Agrupamento adequado.</b></p>
</div>

***

### Referências:
**DATACAMP**. K-Means Clustering in Python: A Practical Guide. Disponível em: <https://www.datacamp.com/tutorial/k-means-clustering-python>.
**GEEKSFORGEEKS**. K-Means Algorithm — A Simple Explanation. Disponível em: <https://www.geeksforgeeks.org/ml-k-means-algorithm/>.
**KDNUGGETS**. Centroid Initialization in K-Means Clustering. Disponível em: <https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html>.
**NEPTUNE.AI.**. K-Means Clustering — An Introduction. Disponível em: <https://neptune.ai/blog/k-means-clustering>.
