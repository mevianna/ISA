## Como Escolher os Centroides Iniciais no K-Means?

A escolha dos **centroides iniciais** no algoritmo K-means é um passo crucial que pode impactar significativamente o resultado final. Uma má escolha pode levar a mínimos locais ou a uma convergência lenta. Por isso, existem diferentes métodos para realizar essa inicialização.

### Pontos de Dados Aleatórios

Nesse método, <span class="math-inline">k</span> **pontos de dados aleatórios** são selecionados do conjunto de dados e usados como centroides iniciais. Cada instância de dados no conjunto precisa ser enumerada e ter um registro do valor mínimo/máximo de cada atributo. No entanto, essa abordagem é considerada **volátil**, pois os centroides selecionados podem não estar bem posicionados, levando a cenários ineficientes.

<div align="center">
<img src="[https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-2-1.jpg?resize=1020%2C534&ssl=1](https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-2-1.jpg?resize=1020%2C534&ssl=1)" alt="k-means-clustering-graph" width="800">
</div>

Como ilustrado no gráfico acima, o centroide representa o centro de um *cluster*. Como o centro desses pontos de dados é inicialmente desconhecido, selecionamos pontos de dados aleatórios e os definimos como centroides para cada *cluster*. Neste exemplo, temos 3 centroides no conjunto de dados.

<div align="center">
<img src="[https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-3.jpg?resize=1020%2C534&ssl=1](https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-3.jpg?resize=1020%2C534&ssl=1)" alt="k-means-clustering-graph" width="800">
</div>

Com os centroides inicializados, os pontos de dados <span class="math-inline">X\_n</span> são atribuídos ao seu centroide de *cluster* mais próximo <span class="math-inline">C</span>. Para isso, é necessário calcular a distância entre o ponto de dados <span class="math-inline">X</span> e o centroide <span class="math-inline">C</span>, geralmente usando a **distância euclidiana**:

<span class="math-block">d\(p, q\) \= \\sqrt\{\\sum\_\{i\=1\}^\{n\} \(q\_i \- p\_i\)^2\}</span>

Posteriormente, um *cluster* será escolhido para cada ponto de dados onde a distância entre o ponto e o centroide seja mínima.

<div align="center">
<img src="[https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-4.jpg?resize=1020%2C534&ssl=1](https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-4.jpg?resize=1020%2C534&ssl=1)" alt="k-means-clustering-graph" width="800">
</div>

Em seguida, os centroides são recalculados pela média de todos os pontos de dados de cada *cluster*, conforme a fórmula:

<span class="math-block">C\_i \= \\frac\{1\}\{\|N\_i\|\} \\sum x\_i</span>

Onde:

* <span class="math-inline">C\_i</span>: é o centroide do grupo <span class="math-inline">i</span>, ou seja, o "centro" do agrupamento, um vetor médio que representa todos os pontos pertencentes a esse grupo.
* <span class="math-inline">\|N\_i\|</span>: é o número de pontos atribuídos ao grupo <span class="math-inline">i</span>.
* <span class="math-inline">\\sum x\_i</span>: é a soma de todos os vetores <span class="math-inline">x\_i</span> que pertencem ao grupo <span class="math-inline">N\_i</span>.

<div align="center">
<img src="[https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-5.jpg?resize=1020%2C534&ssl=1](https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-5.jpg?resize=1020%2C534&ssl=1)" width="800">
</div>

Este processo é repetido até que o número de centroides ideais seja alcançado e as atribuições dos pontos de dados aos *clusters* estejam corretas (ou seja, não haja mais mudanças significativas nas atribuições ou nos centroides).

<div align="center">
<img src="[https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-6.jpg?resize=1020%2C534&ssl=1](https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-6.jpg?resize=1020%2C534&ssl=1)" width="800">
</div>

### Fragmentação Ingênua

A **fragmentação ingênua** é uma estratégia simples para dividir dados em grupos sem considerar sua estrutura ou distribuição real (densidade, distância entre pontos, variabilidade). É utilizada em contextos específicos, como a inicialização de centroides antes de aplicar o K-Means++, divisão de dados para teste e agrupamentos artificiais em simulações.

O método utiliza o valor da soma composta de todos os atributos para uma instância ou linha específica em um conjunto de dados. A ideia é calcular esse valor composto e usá-lo para ordenar as instâncias dos dados.

<div align="center">
<img src="[https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/K-Means-Clustering_12.png?ssl=1](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/K-Means-Clustering_12.png?ssl=1)" width="800">
</div>

**Passos:**

1.  **Passo 1:** Some os atributos de cada instância e adicione a coluna de resultado no início do conjunto de dados.
2.  **Passo 2:** Ordene as instâncias do conjunto de dados pela nova coluna de soma, em ordem crescente.
3.  **Passo 3:** Divida o conjunto de dados horizontalmente em <span class="math-inline">k</span> partes de tamanho igual, ou "fragmentos".

Finalmente, os atributos de cada fragmento são somados e suas médias calculadas. Os valores médios dos atributos de cada fragmento serão identificados como o conjunto de centroides que podem ser usados para a inicialização.

<div align="center">
<img src="[https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/K-Means-Clustering_3.png?ssl=1](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/K-Means-Clustering_3.png?ssl=1)" width="800">
</div>

4.  **Passo 4:** Para cada fragmento, calcule a média das colunas de atributos; os valores médios se tornam os valores correspondentes dos atributos do novo centroide.

Este método ocorre em tempo linear, ou seja, o tempo de execução cresce proporcionalmente à quantidade de dados de entrada, sendo mais eficiente que a inicialização aleatória. No entanto, ainda pode apresentar resultados inconsistentes.

### K-Means++

O **K-Means++** é uma variação do algoritmo K-means que otimiza a escolha dos centroides iniciais, melhorando a qualidade final dos agrupamentos.

O primeiro passo é escolher aleatoriamente um centroide a partir do conjunto de dados. Para os centroides seguintes, calcula-se a distância ao quadrado para cada ponto de dado em relação a cada centroide já escolhido. O próximo centroide é então selecionado com uma probabilidade proporcional à **maior** dessas distâncias ao quadrado. A ideia é que pontos que estão mais **longe** de *todos* os centroides já existentes têm uma **maior chance** de serem escolhidos como o próximo centroide, promovendo uma melhor dispersão inicial.

Apesar da semelhança com o método de escolha aleatória, o K-Means++ é uma **escolha aleatória "inteligente"** por utilizar a distância entre os pontos para guiar essa aleatoriedade.

**Passos:**

1.  Escolha aleatoriamente o primeiro centroide (<span class="math-inline">C\_1</span>).

2.  Para cada ponto de dado <span class="math-inline">x\_i</span>, calcule a maior distância ao quadrado <span class="math-inline">D\_i</span> entre <span class="math-inline">x\_i</span> e qualquer um dos centroides <span class="math-inline">c\_j</span> já selecionados:

    <span class="math-block">D\_i \= \\max\_\{\(j\:1 \\rightarrow k\)\} \\\|x\_i \- c\_j\\\|^2</span>

    Onde:

    * <span class="math-inline">D\_i</span>: a maior distância ao quadrado entre o ponto de dado <span class="math-inline">x\_i</span> e qualquer um dos centroides <span class="math-inline">c\_j</span> já escolhidos.
    * <span class="math-inline">x\_i</span>: o ponto do conjunto de dados.
    * <span class="math-inline">c\_j</span>: um dos centroides já escolhidos.
    * <span class="math-inline">\\\|x\_i \- c\_j\\\|^2</span>: distância euclidiana ao quadrado entre <span class="math-inline">x\_i</span> e <span class="math-inline">c\_j</span>.
    * <span class="math-inline">\\max\_\{\(j\:1 \\rightarrow k\)\}</span>: indica que estamos buscando a distância máxima do ponto <span class="math-inline">x\_i</span> em relação a todos os <span class="math-inline">k</span> centroides que já foram selecionados até o momento.

3.  Escolha um novo ponto de dado <span class="math-inline">x</span> como o próximo centroide com uma probabilidade proporcional a <span class="math-inline">D\_i</span>.

4.  Repita os passos 2 e 3 até que todos os <span class="math-inline">k</span> centroides sejam encontrados.

<div align="center">
<img src="[https://media.geeksforgeeks.org/wp-content/uploads/20190812011808/Screenshot-2019-08-12-at-1.13.15-AM.png](https://media.geeksforgeeks.org/wp-content/uploads/20190812011808/Screenshot-2019-08-12-at-1.13.15-AM.png)" width="800">
</div>

<div align="center">
<img src="[https://media.geeksforgeeks.org/wp-content/uploads/20190812011831/Screenshot-2019-08-12-at-1.09.42-AM.png](https://media.geeksforgeeks.org/wp-content/uploads/20190812011831/Screenshot-2019-08-12-at-1.09.42-AM.png)" width="800">
</div>

### Referências:

* <a href="[https://www.geeksforgeeks.org/ml-k-means-algorithm/](https://www.geeksforgeeks.org/ml-k-means-algorithm/)">[https://www.geeksforgeeks.org/ml-k-means-algorithm/](https://www.geeksforgeeks.org/ml-k-means-algorithm/)</a>
* <a href="[https://neptune.ai/blog/k-means-clustering](https://neptune.ai/blog/k-means-clustering)">[https://neptune.ai/blog/k-means-clustering](https://neptune.ai/blog/k-means-clustering)</a>
* <a href="[https://www.datacamp.com/tutorial/k-means-clustering-python](https://www.datacamp.com/tutorial/k-means-clustering-python)">[https://www.datacamp.com/tutorial/k-means-clustering-python](https://www.datacamp.com/tutorial/k-means-clustering-python)</a>
* <a href="[https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)">[https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)</a>

