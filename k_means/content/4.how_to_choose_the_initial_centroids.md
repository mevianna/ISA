## English Version


## Portuguese Version


## Como escolher os centroides iniciais?
A escolha dos centroides no algoritmo K-means √© um passo fundamental que pode impactar fortemente o resultado final. Com isso, uma m√° escolha pode levar a m√≠nimos locais ou lentid√£o na converg√™ncia, portanto existem m√©todos para realizar a inicializa√ß√£o de centroide.

## Pontos de dados aleat√≥rios
Nesse m√©todo os k pontos de dados aleat√≥rios s√£o selecionados do conjunto de daos e usados como centr√≥ides iniciais, cada inst√¢ncia de dados no conjunto ter√° que ser enumerada e apresentar um registro do valor m√≠nimo/m√°ximo de cada tributo, logo sendo considerado uma abordagem muito vol√°til e que prev√™ um cen√°rio em que os centr√≥ides selecionados n√£o est√£o bem posicionados.

<div align="center">
<img src= "https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-2-1.jpg resize=1020%2C534&ssl=1" alt="k-means-clustering-graph" width="800">
</div>

Como mostrado no gr√°fico acima, o centroide √© o centro de um cluster, contudo, o centro desses pontos de dados √© desconhecidos, ent√£o, selecionamos pontos de dados aleat√≥rios e os definimos como centroides para cada cluster e, nesse caso, existem 3 centroides no conjunto de dados.

<div align="center>
<img src="https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-3.jpg?resize=1020%2C534&ssl=1" alt="k-means-clustering-graph" width="800">
</div>
Com o centr√≥ides inicializados, os pontos de dados Xn s√£o atribu√≠dos ao seu centr√≥ide de cluster mais pr√≥ximo C. Ademais, nesta etapa, torna-se necess√°rio calcular a dist√¢ncia entre o ponto de dados X e o centroide C.

$$d(p, q) = \sqrt{\sum_{i=1}^{n} (q_i - p_i)^2}$$

Posteriormente,um cluster ser√° escolhido para pontos de dados onde a dist√¢ncio entre o ponto de dados e o centroide seja m√≠nima.

<div align="center>
<img src="https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-4.jpg?resize=1020%2C534&ssl=1" alt="k-means-clustering-graph" width="800">
</div>

Assim, os centr√≥ides s√£o reinicializados com o c√°lculo da m√©dia de todos os pontos de dados de cada cluster.

$C_i = \frac{1}{|N_i|} \sum x_i$.

***Ci: √© o centr√≥ide do grupo i, ou seja, o "centro" do agrupamento - um vetor m√©dio que representa todos os pontos pertencentes a esse grupo.
***Ni: √© o conjunto de pontos atribu√≠dos ao grupo i.
***‚àëùë•i: √© a soma de todos os vetores xi, que pertencem ao grupo Ni.

<div align="center>
<img src="https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-5.jpg?resize=1020%2C534&ssl=1" width="800">
</div>

 A partir disso, o processo ser√° repetido at√© que chegue ao n√∫mero de centroides ideais e as atribui√ß√µes de pontos de dados ao clusters corretos.

 <div align="center>
<img src="https://i0.wp.com/neptune.ai/wp-content/uploads/2024/04/k-means-clustering-6.jpg?resize=1020%2C534&ssl=1" width="800>
 </div>

 ## Fragmenta√ß√£o ing√™nua
 A fragmenta√ß√£o ing√™nua √© uma estrat√©gia simples para dividir dados em grupos (clusters) sem considerar a estrutura ou distribui√ß√£o real dos dados, por essa raz√£o de n√£o considerar a densidade, dist√¢ncia entre pontos ou variabilidade, sendo utilizado em contextos como: inicializa√ß√£o de centr√≥idos antes de aplicar o k-means++, divis√£o de dados para teste e agrupamentos artificias em simula√ß√µes. Assim, utiliza-se o valor da soma composta de todos os atributos para uma inst√¢ncia ou linha espec√≠fica em um conjunto de dados, ou seja, a ideia √© calcular o valor composto e us√°-lo para ordernar as inst√¢ncias dos dados. 

  <div align="center>
<img src="https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/K-Means-Clustering_12.png?ssl=1" width="800>
 </div>

 *** Passo 1:**
Some os atributos de cada inst√¢ncia e adicione a coluna de resultado no in√≠cio do conjunto de dados.

*** Passo 2:**
Ordene as inst√¢ncias do conjunto de dados pela nova coluna de soma, em ordem crescente.

*** Passo 3:**
Divida o conjunto de dados horizontalmente em ùëò partes de tamanho igual, ou fragmentos.

Finalizando, os atributos de cada fragmento ser√£o somados e suas m√©dias ser√£o calculadas. Os valores m√©dios dos atributos do fragmento ser√° identificada como conjunto de centroides que podem ser usados para inicializa√ß√£o.

<div align="center>
<img src="https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/K-Means-Clustering_3.png?ssl=1" width="800>
 </div>

 *** Passo 4:**
Para cada fragmento, calcule a m√©dia das colunas de atributos; os valores m√©dios se tornam os valores correspondentes dos atributos do novo centr√≥ide

 Por ocorrer em tempo linear, ou seja, o tempo que o algoritmo leva para ser executado cresce proporcionalmente √† quantidade de dados de entrada, portanto sendo muito melhor que a da inicializa√ß√£o aleat√≥ria, entretanto, ela apresenta os mesmos problemas de ter a chance de apresentar resultados inconsistentes.

**K-Means ++:
O K-Means √© uma varia√ß√£o do algoritmo K-means que otimiza a escolha dos centr√≥ides iniciais dos grupos, al√©m de melhor a qualidade de atribui√ß√£o final dos agrupamentos.
O primeiro passo dessa inicializa√ß√£o √© escolher de forma aleat√≥ria um centr√≥ide a partir do conjunto de dados. Para os pr√≥ximos centr√≥ides, √© c√°lculo a dist√¢ncia de cada ponto de dados at√© o centr√≥ide mais pr√≥ximo j√° escolhido. Com isso, o pr√≥ximo √© escolhido a partir da probabilidade proporcional √† dist√¢ncia de um ponto at√© o centr√≥ide mais pr√≥ximo, logo quanto maior essa dist√¢ncia, maior a chance de o ponto ser escolhido.
Apesar de sua semelhan√ßa com m√©todo da escolha aleat√≥ria, o K-means √© uma escolha aleat√≥ria com intelig√™ncia por utilizar a dist√¢ncia entre os pontos para guiar essa aleatoriedade.

** Passos:**
1.Escolha aleatoriamente o primeiro centr√≥ide (C1).
2.Calcular a dist√¢ncia entre todos os pontos de dados e o centr√≥ide selecionado

$$D_i = \max_{(j:1 \rightarrow k)} \|x_i - c_j\|^2$$

*** Di: dist√¢ncia m√≠nima ao quadrado entre o ponto de dado xi e o centr√≥ide mais pr√≥ximo.
*** xi: o ponto do conjunto de dados.
*** cj: centr√≥ide j√° escolhido.
*** ‚à•xi-cj‚à• ^2: dist√¢ncia euclidiana ao quadrado entre xi e cj.
*** max: o valor m√°ximo entre um conjunto de valores.
‚Äã*** (j:1‚Üík): Isso descreve o conjunto de valores sobre os quais estamos encontrando o m√°ximo. Indica que estamos iterando sobre um √≠ndice j que varia de 1 a k. Geralmente, j refere-se a diferentes "centros" ou "prot√≥tipos" em um algoritmo de agrupamento (clustering), como o K-Means. k seria o n√∫mero total de centros ou clusters.

3. Inicialize o ponto de dados x como novo centr√≥ide.
4. Repita os passos de 3 e 4 at√© que todos clusters sejam encontrados.‚Å°

<div align="center>
<img src="https://media.geeksforgeeks.org/wp-content/uploads/20190812011808/Screenshot-2019-08-12-at-1.13.15-AM.png" width="800>
 </div>

<div align="center>
<img src="https://media.geeksforgeeks.org/wp-content/uploads/20190812011831/Screenshot-2019-08-12-at-1.09.42-AM.png" width="800>
 </div>

### Refer√™ncias:
 https://www.geeksforgeeks.org/ml-k-means-algorithm/
 https://neptune.ai/blog/k-means-clustering
 https://www.datacamp.com/tutorial/k-means-clustering-python
 https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html


