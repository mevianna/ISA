# English Version

The selection of the number of clusters, i.e., k, is one of the main factors in K-Means. Poor initialization may lead to issues in the algorithm’s results. Therefore, there are techniques that help in choosing k, as presented below.

## Choosing the Optimal Number of Clusters (Elbow Method)

Inertia helps determine the optimal number of clusters ($k$). By plotting inertia for different values of $k$, we expect to see a decrease in inertia as $k$ increases. At some point, this decrease becomes less significant, forming an "elbow."

From this, the elbow method emerged as a graphical way to determine the number of clusters. It measures the Euclidean distance between each data point and its centroid and chooses the number of clusters based on the point at which the change in the "within-cluster sum of squares" stabilizes. This value represents the total variance within each cluster, which is plotted against the number of clusters.

The first step of the elbow method is to calculate the WCSS (Within-Cluster Sum of Squares) for each number of clusters ($k$). Then, the WCSS value is plotted on the y-axis, and the number of clusters on the x-axis. As the number of clusters increases, the points on the graph should form a consistent pattern. From this pattern, a range for the optimal number of clusters can be identified. When deciding the number of clusters, it is important to consider computational costs. The larger the number of clusters, the more processing power is required, especially with large datasets.

<div align="center"> <img src="https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/88/64/k-means-clustering-graph.png" alt="k-means-clustering-graph" width="800"> <p align="center"><b>The elbow represents the balance point, so 3 is a good number of clusters.</b></p> </div>

## Choosing the Optimal Number of Clusters (Silhouette Method)

In the Silhouette method, a coefficient is analyzed based on the distance between centroids, considering how well the data is grouped. Thus, the horizontal bar chart shows, for each cluster, the coefficient value of the closest versus the farthest data points, forming a "silhouette." It is also used as an internal validation metric.

The silhouette coefficient ranges from -1 to +1, where "+1" represents the greatest separation between clusters, "0" would be the borderline case, and a negative value means the data may have been clustered incorrectly.

The calculation of the silhouette coefficient depends on two measures:

* $a(i)$ is the average distance between data point $i$ and all other points in the same cluster as $i$;

* $b(i)$ is the lowest average distance between data point $i$ and all points in any other cluster different from its own.

Thus, the formula is given by:


$$s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}$$

​This calculation is performed for all points in the dataset. Then, the arithmetic mean of all individual coefficients is computed to obtain the overall silhouette score, which indicates the quality of the entire clustering.

> [!NOTE]
> When there is only one cluster ($k=1$), there is no second group to compare distances with. Therefore, $b(i)$ cannot be computed, making the silhouette coefficient undefined. For this reason, the silhouette method cannot be applied for $k=1$.

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*SqMaMMzbiS9h4Jj_47akug.png" alt="Gráfico de Silhueta com 2 Clusters" width="800">
</div>

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*vzNSANw8qh-2GG9INGzGLQ.png" alt="Gráfico de Silhueta com 3 Clusters" width="800">
</div>

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*tzeZg6vMMTNpevs4Wdfo-A.png" alt="Gráfico de Silhueta com 4 Clusters" width="800">
</div>

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*7F_ujfWnh2lfbGspaFKM1g.png" alt="Gráfico de Silhueta com 5 Clusters" width="800">
</div>

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Eg3O6kcJiF7vAWY9RieLfw.png" alt="Gráfico de Silhueta com 6 Clusters" width="800">
</div>

The `n_clusters values` 3, 5, and 6 have clusters with coefficients below the average value (dashed red line), i.e., negative values, and therefore should be discarded from the analysis, leaving `n_clusters` 2 and 4. The first shows greater separation between its clusters, while 4 has clusters of similar size, suggesting it as the best choice for the number of clusters.

***

### References

**CWI SOFTWARE**. Understanding Clusters and K-Means. Medium, Jul 23, 2020. Available at: https://medium.com/cwi-software/entendendo-clusters-e-k-means-56b79352b452

**DATACAMP**. Euclidean Distance: A Complete Guide. Available at: https://www.datacamp.com/pt/tutorial/euclidean-distance

**DATACAMP**. K-Means Clustering in Python: A Practical Guide. Available at: https://www.datacamp.com/tutorial/k-means-clustering-python

**IBM**. K-means Clustering. Available at: https://www.ibm.com/think/topics/k-means-clustering

***

## Contributors
<img loading="lazy" src="https://avatars.githubusercontent.com/u/207051125?s=400&u=985341a59692bda296ac3e384872f8d5d92fb51a&v=4" width=115><br><sub>Arthur Bogoni (https://github.com/ArthurBogoni
)

***

# Portuguese Version

A seleção do número de clusters, isto é, o *k*, é um dos prinicpias fatores do K-Means. Uma inicialização ruim pode ocasionar problemas no resultado do algoritmo. Por isso, existem técnicas que auxiliam na escolha do *k*, conforme apresentadas a seguir.

## Seleção do Número Ideal de Clusters (Método do Cotovelo)
A inércia auxilia na determinação do número ideal de clusters ($k$). Ao plotar a inércia para diferentes valores de $k$, espera-se observar uma queda na inércia à medida que $k$ aumenta. Em algum ponto, essa queda se torna menos significativa, formando um "cotovelo".

A partir disso, surgiu o método do cotovelo, uma maneira gráfica de determinar o número de agrupamentos. Ele mede a distância euclidiana entre cada ponto de dado e seu centróide e escolhe o número de agrupamentos com base no ponto em que a mudança na "soma dos quadrados dentro do agrupamento" se estabiliza. Esse valor representa a variância total dentro de cada agrupamento, que é plotada contra o número de agrupamentos.

O primeiro passo do método do cotovelo é calcular o WCSS para cada número de clusters ($k$). Em seguida, o valor de WCSS é plotado no eixo y e o número de agrupamentos no eixo x. À medida que o número de agrupamentos aumenta, os pontos do gráfico devem formar um padrão consistente. A partir desse padrão, obtém-se uma faixa para o número ótimo de agrupamentos. Ao decidir o número de agrupamentos, é importante considerar os custos computacionais. Quanto maior o número de agrupamentos, mais poder de processamento é necessário, especialmente com conjuntos de dados grandes.

<div align="center">
  <img src="https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/88/64/k-means-clustering-graph.png" alt="k-means-clustering-graph" width="800">
    <p align="center"><b> O cotovelo representa o equilíbrio, logo 3 é um bom número de clusters.</b></p>


</div>
</div>

## Seleção do Número Ideal de Clusters (Método da Silhueta)
No método da Silhueta, é analisado um coeficiente resultante do cálculo da distância entre os centróides, levando em consideração o agrupamento dos dados. Sendo assim, o gráfico em barras horizontais mostra, para cada cluster, o valor do coeficiente dos dados mais próximos aos mais distantes, formando uma "silhueta". Ele também é utilizada como métrica de validação interna.

O coeficiente da silhueta fica entre o intervalo de -1 a +1, em que "+1" representa a maior distância entre os clusters, "0" seria a aproximação do ponto de decisão e um valor negativo significa que, possivelmente, os dados estão agrupados de forma inadequada. 

O cálculo do coeficiente de silhueta depende de duas medidas:
* a(i)$ é a distância média entre o ponto de dado $i$ e todos os outros pontos no *mesmo cluster* que $i$;
* $b(i)$ é a menor distância média entre o ponto de dado $i$ e todos os pontos em *qualquer outro cluster* diferente do seu.

Assim, a fórmula é dado por:

$$s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}$$

Esse cálculo é feito para todos os pontos do conjunto de dados. Em seguida, é calculada a média aritmética de todos os coeficientes individuais para obter o coeficiente média da silhueta, que indica a qualidade de todo o agrupamento.

> [!NOTE]
> Quando há apenas um cluster (k=1), não existe um segundo grupo com o qual comparar as distâncias. Assim, a distância $$b(i)$$ não pode ser calculada, tornando o coeficiente de silhueta indefinido. Por isso, o método da silhueta não pode ser aplicado para k = 1.

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*SqMaMMzbiS9h4Jj_47akug.png" alt="Gráfico de Silhueta com 2 Clusters" width="800">
</div>

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*vzNSANw8qh-2GG9INGzGLQ.png" alt="Gráfico de Silhueta com 3 Clusters" width="800">
</div>

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*tzeZg6vMMTNpevs4Wdfo-A.png" alt="Gráfico de Silhueta com 4 Clusters" width="800">
</div>

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*7F_ujfWnh2lfbGspaFKM1g.png" alt="Gráfico de Silhueta com 5 Clusters" width="800">
</div>

<div align="center">
<img src= "https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Eg3O6kcJiF7vAWY9RieLfw.png" alt="Gráfico de Silhueta com 6 Clusters" width="800">
</div>

Os `n_clusters` 3, 5 e 6 possuem clusters com coeficiente abaixo do valor médio (tracejado em vermelho), ou seja, são negativos, portanto devem ser descartados da análise, sobrando `n_clusters` 2 e 4. O primeiro apresenta maior diferença entre seus clusters, enquanto o 4 possui tamanhos similares, sugerindo ser a melhor escolha para a quantidade de clusters.

## Referências
**CWI SOFTWARE**. Entendendo clusters e K-Means. Medium, 23 jul. 2020. Disponível em: <https://medium.com/cwi-software/entendendo-clusters-e-k-means-56b79352b452>.

**DATACAMP**. Euclidean Distance: A Complete Guide. Disponível em: <https://www.datacamp.com/pt/tutorial/euclidean-distance>.

**DATACAMP**. K-Means Clustering in Python: A Practical Guide. Disponível em: <https://www.datacamp.com/tutorial/k-means-clustering-python>.

**IBM**. K-means Clustering. Disponível em: <https://www.ibm.com/think/topics/k-means-clustering>.

## Contribuidores
| <img loading="lazy" src="https://avatars.githubusercontent.com/u/207051125?s=400&u=985341a59692bda296ac3e384872f8d5d92fb51a&v=4" width=115><br><sub>Arthur Bogoni (https://github.com/ArthurBogoni) |
| :---: | 
