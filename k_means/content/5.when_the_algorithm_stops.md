## English version

Now that we understand how to define the number of centroids and clusters—essential elements for the algorithm’s operation—a natural question arises: when does the algorithm stop? In other words, what is the stopping criterion for the algorithm? Generally, the algorithm terminates under two main conditions: when convergence is reached or when a predefined maximum number of iterations is completed. These two situations are explained below.

## Convergence

Convergence in K-Means occurs when the algorithm reaches a state of stability where the variation in the centroids' positions is so small that it can be considered insignificant. This state indicates that the algorithm has efficiently grouped the data into clusters, and subsequent iterations will not bring relevant changes, as the results will be practically the same.

### How to Identify Convergence?
In short, convergence can be identified in 3 ways:

* **Null or low change in centroids:**
Convergence is achieved when the centroids do not change position or when they move an extremely small distance. Usually, a minimum displacement for the centroids is predefined; if the displacement falls below it, the algorithm is considered to have converged. For this verification, the distance between the centroid's current position and its position in the previous iteration is calculated at each iteration.

* **Stabilization of points:**
In addition to centroid stability, convergence can also be identified when point assignments to clusters do not change in consecutive iterations. That is, if all points remain associated with the same clusters in two or more consecutive iterations, the algorithm can be terminated. To do this, simply compare each point's cluster assignment in the current iteration and the previous iteration.

* **Inertia analysis:**
Another way to analyze whether the algorithm has converged is by calculating inertia, discussed in [2.Fundamental Concepts](https://github.com/mevianna/ISA/tree/k_means/k_means/content/2.fundamental_concepts.md). Thus, inertia is calculated for all points and their respective centroids in the current iteration. Then, the difference between the obtained inertia and that obtained in the previous iteration is analyzed: if this difference is less than an initially established value, the algorithm has converged and can terminate.

### Factors Influencing Convergence
In the K-Means algorithm, some factors can influence or hinder convergence. For example, poor centroid initialization can:

* Increase the time it takes for the algorithm to stabilize;
* Lead to a suboptimal division of the data, that is, reaching a local minimum—a stable configuration that is not necessarily the best possible Thus, although the result may not be the "global optimum" (the best possible solution), it is reasonable but inferior to other potential solutions.

> An example of the second case is imagining a dataset clearly divided into two groups, A and B. However, a poor initialization might select two centroids belonging to group A. In this scenario, the algorithm tends to split group A into two clusters, while group B is ignored or incorrectly clustered. Therefore, even if convergence is achieved, the cluster division is imperfect.

Another issue related to convergence is the presence of outliers (points that do not follow the pattern). These points can cause the centroids to shift during iterations, resulting in potentially low-quality solutions and increasing the convergence time.

> [!NOTE]
> To understand the most common errors, such as the presence of outliers, visit: [7. Possible Problems](https://github.com/mevianna/ISA/tree/k_means/k_means/content/7.possible_problems.md)

Additionally, variable cluster density can also be an issue: centroids tend to adjust more quickly to denser groups, while they take longer to adapt to less dense groups. This can cause the algorithm to assign points belonging to less dense clusters into denser ones, or even merge one cluster into another.

Finally, the non-spherical shape of clusters can also hinder performance. Since K-Means tends to assume clusters are spherical, it may assign points to the nearest centroid even if, in the ideal solution, those points belong to clusters with irregular or overlapping shapes. Consequently, the quality of clustering may be compromised.

## Iteration Limit
In some cases, the algorithm may take a long time to converge or even enter an infinite loop of iterations due to outliers, complex datasets, or a large number of clusters. To prevent excessively long processing times, a maximum number of iterations is set. When this limit is reached, the algorithm stops, even if ideal convergence has not been achieved.

Among the advantages of this method are controlling execution time, avoiding excessive computational resource consumption, and preventing infinite cycles. However, an inappropriate choice of this limit can cause problems:

* Too low a limit: the algorithm may stop before reaching an adequate solution;
* Too high a limit: computational cost may outweigh the quality gained, making the effort unjustifiable.

Therefore, selecting this limit requires evaluating the size and complexity of the dataset, the desired quality level, and available computational resources, since each situation needs a specific assessment. Generally, commonly used limits range between 100 and 300 iterations. It is worth noting that with a high iteration limit, the algorithm may stop earlier if convergence is reached beforehand.

### Other Stopping Criteria
In certain cases, other stopping criteria may be defined. For example, a maximum execution time can be set, forcing K-Means to terminate once reached. In some versions of K-Means, errors such as empty clusters (i.e., no points assigned to a centroid) also cause the algorithm to terminate.

## References:
**BISHOP, C. M.**. Pattern Recognition and Machine Learning. New York: Springer, 2006. Available at: <https://www.microsoft.com/en-us/research/wp-content/uploads/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf>. Accessed: May 30, 2025.
**ESTADÍSTICAS FÁCILES**. What does k convergence mean? Available at: <https://es.statisticseasily.com/glosario/¿Qué-significa-k-convergencia%3F>. Accessed: May 30, 2025.
**IBM.** K-means clustering. Available at: <https://www.ibm.com/think/topics/k-means-clustering>. Accessed: May 14, 2025.
**SCIKIT-LEARN**. sklearn.cluster.KMeans. Available at: <https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html>. Accessed: May 14, 2025.

***

## Portuguese version

Agora que já sabemos como definir o número de centróides e clusters, elementos essenciais para o funcionamento do algoritmo, pode surgir a seguinte dúvida: até quando o algortimo é executado? Em outras palavras, **qual o critério de parada do algoritmo?** Geralmente, o algoritmo finaliza em duas situações principais: quando é atingido ou a convergência ou o número de iterações previamente estipulado. Estas duas situações são abordadas em seguida.

## Convergência

A convergência no K-Means acontece quando o algoritmo alcança um estado de estabilidade em que a variação da posição dos centróides é tão pequena que pode ser considerada insignificante. Esse estado indica que o algoritmo agrupou eficientemente os dados nos clusters e as iterações seguintes não trarão mudanças relevantes, pois os resultados serão praticamente os mesmos.

### Convergência: como identifcar?
A convergência, em suma, pode ser identificada de 3 formas:

* **Nula ou baixa mudança nos centróides:**
A convergência é alcançada quando os centróides não mudam de posição ou quando se movem uma distância extremamente baixa. Normalmente, é pré-definido um deslocamento minímo para os centróides; caso fique abaixo dele, é considerado que o algoritmo convergiu. Para essa verificação, a cada iteração calcula-se a distância entre a posição atual do centróide e a sua posição na iteração anterior.

* **Estabilização dos pontos**
Além da estabilidade dos centróides, também é possível identificar convergência quando as atribuições dos pontos aos clusters não mudam em iterações consecutivas. Ou seja, se todos os pontos continuarem associados aos mesmos clusters em duas ou mais iterações seguidas, o algoritmo pode ser encerrado. Para isso, basta comparar a atribuição de cluster de cada ponto na iteração atual e na iteração anterior.

* **Análise da inércia**
Outra forma de analisar se o algoritmo convergiu, é por meio do cálculo da inércia, abordado em [2.Conceitos fundamentais](https://github.com/mevianna/ISA/tree/k_means/k_means/content/2.fundamental_concepts.md). Dessa forma, a inércia é calculada para todos os pontos e seus respectivos centróides na iteração atual. Em seguida, analisa-se a diferença da inércia obtida com àquela obtida na iteração anterior: caso essa diferença seja inferior a um valor estabelicido inicialmente, o algoritmo convergiu e pode encerrar. 

### Fatores que influenciam a convergência
No algoritmo K-Means, alguns fatores podem influenciar ou dificultar a convergência. Por exemplo, uma má inicialização dos centróides pode:

* Aumentar o tempo de estabilização do algoritmo;
* Levar a uma divisão não tão boa dos dados, isto é, obter um minímo local, que é uma configuração estável mas não necessariamente é a melhor possível. Assim, o resultado embora não seja o "ótimo global" (melhor solução possível), ele é razoável mas inferior a outras possíveis soluções.

> Um exemplo desse segundo caso é imaginar um conjunto de dados bem definidos em 2 grupos, A e B. Entretanto, uma inicialização inadequada escolhe dois centróides pertecentes ao grupo A. Dessa forma, o algorimo tende a dividir o grupo A em dois grupos, enquanto que o grupo B é ignorado ou agrupado incorretamente. Portanto, mesmo que haja convergência, a divisão dos clusters é imperfeita.

Outro problema em relação a convergência é a existência dos outliers (pontos fora do padrão). Esses pontos podem causar deslocamentos nos centróides no decorrer das interações, resultando em possíveis soluções de baixa qualidade e aumentando o tempo de convergência.

> [!NOTE]
> Para entender possíveis erros mais comuns, como a presença de outliers, acesse: [7. Possiveis problemas](https://github.com/mevianna/ISA/tree/k_means/k_means/content/7.possible_problems.md)

Além disso, a densidade variável dos grupos também pode ser um problema: os centróides tendem a se ajustar mais rapidamente aos grupos mais densos, enquanto demora mais em grupos menos densos. Isso pode levar o algoritmo a agrupar pontos pertencentes aos grupos menos densos em grupos mais densos, ou até mesmo englobando um grupo no outro.

Por fim, a forma não esférica dos grupos também pode atrapalhar. Como o K-Means tende a considerar o conjunto de dados como esféricos, ele pode atribuir pontos ao centróide mais próximo, mesmo que, na solução ideal, esses pontos pertençam a clusters de formatos irregulares ou sobrepostos. Assim, a qualidade do agrupamento pode ser prejudicada.

## Limite de iterações

Em alguns casos, o algoritmo pode demorar muito para convergir ou até mesmo entrar em um ciclo infinito de iterações, devido à presença de outliers, ao conjunto complexo de dados ou à presença de muitos clusters. Para evitar que o processo seja prolongado excessivamente, é estipulado um limite de iterações. Quando esse limite é atingido, o algoritmo para, mesmo que a convergência ideal não tenha sido atingida.

Entre as vantagens desse método, há o controle do tempo de execução, evitando o consumo excessivo de recursos computacionais e ciclos infinitos. No entanto, a escolha inadequada de um valor para o limite pode ocasionar problemas:

* Limite muito baixo: algoritmo pode ser finalizado antes de uma solução adequada;
* Limite muito alto: o custo computacional pode ser superior a qualidade atingida, o que pode não justificar o esforço.

Portanto, para a escolha do valor desse limite, é preciso avaliar o tamanho, a complexidade do conjunto de dados, o nível de qualidade desejado e até mesmo os recursos computacionais disponíveis, pois cada situação necessita de uma avaliação específica. Em geral, os valores mais utilizados como limites giram em torno de 100 e 300 iterações. Cabe ressaltar que, em casos de um número muito alto de execuções, é possível que o algoritmo encerre antes, caso a convergência seja atingida previamente.

### Outros critérios de parada

Em determinados casos, outros critérios de parada podem ser determinados. Por exemplo, pode ser definido um tempo máximo de execução do algoritmo que, quando atingido, força a finalização do K-Means. Em algumas versões do K-Means, em casos de erro, como a formação de clusters vazios (isto é, nenhum ponto atribuído a um centróide), o algortimo também é finalizado.

### Referências:
**BISHOP, C. M.**. Pattern Recognition and Machine Learning. New York: Springer, 2006. Disponível em: <https://www.microsoft.com/en-us/research/wp-content/uploads/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf>. Acesso em: 30 mai. 2025.
**ESTADÍSTICAS FÁCILES**. ¿Qué significa k convergencia? Disponível em: <https://es.statisticseasily.com/glosario/¿Qué-significa-k-convergencia%3F>. Acesso em: 30 maio 2025.
**IBM**. K-means clustering. Disponível em: <https://www.ibm.com/think/topics/k-means-clustering>. Acesso em: 14 maio 2025.
**SCIKIT-LEARN**. sklearn.cluster.KMeans. Disponível em: <https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html>. Acesso em: 14 maio 2025.