# English Version

## What is K-Means Clustering?
K-means clustering is a widely used unsupervised learning algorithm designed to group unlabeled data into clusters, meaning that the data points do not have a predefined classification structure. Moreover, this form of clustering assumes that a data point can belong to only one cluster. The clusters are formed around centroids, which are calculated as the mean of all points in a cluster, depending on the characteristics of the data.

## Objective 
The goal of this algorithm is to minimize the sum of distances between the data points and their assigned cluster centroids. Data points that are closer to a centroid are grouped into the same category. A higher value of k (number of clusters) indicates smaller clusters with greater detail, while a lower value of k results in larger clusters with less detail.

## History
The K-means method emerged from pioneering work in statistics and signal processing. The fundamental idea of minimizing the sum of squared distances was proposed almost simultaneously by several researchers.

The initial concept was introduced by Hugo Steinhaus in 1956, who presented the idea of partitioning a set of points into groups by minimizing internal distances. Later, the algorithm was formalized and redefined by Stuart Lloyd in 1957 while working at Bell Labs.

### 1960s: Popularization

In 1967, James MacQueen gave the algorithm the name K-means and helped popularize the method by proposing a more practical version applicable to multidimensional data. He also introduced the idea of updating the centroids as data points were assigned to clusters, whereas Lloyd’s original version used a batch approach.

### 1970s and 1980s: Consolidation

The algorithm became established as one of the standard clustering techniques. Its simplicity and efficiency made K-means a common choice in practical problems.

### 2000s: Improvements and Variants

K-means++ (2007): Improved centroid initialization to avoid unsatisfactory results;

Fuzzy C-means: Allows a point to belong to more than one cluster with degrees of membership;

Mini-Batch K-means: Adapted for large datasets by using smaller samples.

### Present Day: A Classic Algorithm

Today, K-means is widely used in various fields such as data analysis, unsupervised learning, and data mining. Despite its limitations, it remains a fundamental method due to its efficiency and simplicity.

*** 

### References

DATACAMP. K-Means Clustering in Python: A Practical Guide. Available at: https://www.datacamp.com/tutorial/k-means-clustering-python
.
IBM. K-means Clustering. Available at: https://www.ibm.com/think/topics/k-means-clustering
.

***

### Contributors
<img loading="lazy" src="https://avatars.githubusercontent.com/u/207051125?s=400&u=985341a59692bda296ac3e384872f8d5d92fb51a&v=4" width=115><br><sub>Arthur Bogoni (https://github.com/ArthurBogoni
)

***

# Portuguese Version

## O que é K-Means Clustering?
O K-means clustering é um algoritmo de aprendizado não supervisionado amplamente utilizado para agrupar dados não rotulados em clusters, o que significa que os pontos de dados não têm uma estrutura de classificação definida. Ademais, essa forma de agrupamento estipula que um ponto de dados pode existir em apenas um cluster, os quais são formados em torno de centróides, que são calculados como a média de todos os pontos em um cluster, dependendo das características dos dados.

## Objetivo
O objetivo desse algoritmo é minimizar a soma das distâncias entre os pontos de dados e seus agrupamentos atribuídos. Pontos de dados que estão mais próximos de um centróide são agrupados na mesma categoria. Um valor maior de k (número de clusters), ou número de agrupamentos, indica agrupamentos menores e com um maior nível de detalhe, enquanto um valor menor de k resulta em agrupamentos maiores e com menor detalhe.

## História
O método K-means surgiu a partir de trabalhos pioneiros na área de estatísticas e processamento de sinais. A ideia fundamental de minimizar a soma das distâncias quadráticas foi proposta por diversos pesquisadores quase simultaneamente.

O conceito inicial foi introduzido por Hugo Steinhaus em 1956, que apresentou a ideia de particionar um conjunto de pontos em grupos minimizando as distâncias internas. Posteriormente, o algoritmo foi formalizado e redefinido por Stuart Lloyd em 1957, enquanto trabalhava nos laboratórios da Bell.

### Década de 1960: Popularização
Em 1967, James MacQueen deu o nome "K-means" ao algoritmo e contribuiu para a popularização do método ao propor uma versão mais prática e aplicável para dados multidimensionais. Além disso, introduziu a ideia de atualizar os centróides conforme os dados eram atribuídos aos clusters, enquanto a versão original de Lloyd utilizava uma abordagem em batch.

### Década de 1970 e 1980: Consolidação
O algoritmo se consolidou como uma das técnicas padrão de agrupamento. A simplicidade e a eficiência tornaram o K-means uma escolha comum em problemas práticos.

### Década de 2000: Melhorias e Variantes
* **K-means++ (2007):** Melhorou a inicialização dos centróides para evitar resultados insatisfatórios;

* **Fuzzy C-means:** Permite que um ponto pertença a mais de um cluster com graus de pertinência;

* **Mini-Batch K-means:** Adaptado para grandes conjuntos de dados, utilizando amostragens menores.

### Atualidade: Um Algoritmo Clássico
Hoje, o K-means é amplamente utilizado em várias áreas, como análise de dados, aprendizado não supervisionado e mineração de dados. Apesar de suas limitações, ele continua sendo um método fundamental pela sua eficiência e simplicidade.

***

## Referências
**DATACAMP**. K-Means Clustering in Python: A Practical Guide. Disponível em: <https://www.datacamp.com/tutorial/k-means-clustering-python>.
**IBM**. K-means Clustering. Disponível em: <https://www.ibm.com/think/topics/k-means-clustering>.
***
## Contribuidores
| <img loading="lazy" src="https://avatars.githubusercontent.com/u/207051125?s=400&u=985341a59692bda296ac3e384872f8d5d92fb51a&v=4" width=115><br><sub>Arthur Bogoni (https://github.com/ArthurBogoni) |
| :---: | 
